{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/audalsgh/20250801/blob/main/assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5101d226-325d-407a-82d7-5b221da9ce69",
      "metadata": {
        "id": "5101d226-325d-407a-82d7-5b221da9ce69"
      },
      "source": [
        "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53007a3d-38ff-4cd1-859b-0ced1e8500cd",
      "metadata": {
        "id": "53007a3d-38ff-4cd1-859b-0ced1e8500cd"
      },
      "source": [
        "## Assessment: Building a Real-Time Video AI Application ##\n",
        "In this notebook, you will utilize what you've learned in this course to complete an assessment. The assessment has been divided into a couple of steps - each of which will generate a text file for grading purposes. You will be graded based on the following rubric. Note that this coding portion does not give partial credit - it shows up as either 0 or 60 points. Earning 50 points or more will award you the full 60 points, while earning less than 50 points will award you 0 points for the coding portion.\n",
        "<table border=\"1\" class=\"dataframe\" align='left'>  <thead>    <tr style=\"text-align: right;\">      <th>Step</th>      <th># of &lt;FIXME&gt;</th>      <th>Points</th>    </tr>  </thead>  <tbody>    <tr>      <td>0. The Problem</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>1. Understanding the Input Video</td>      <td>5</td>      <td>10</td>    </tr>    <tr>      <td>2. Brainstorm AI Inference and Download a Pre-Trained Model</td>      <td>2</td>      <td>10</td>    </tr>    <tr>      <td>3. Edit the Inference Configuration File</td>      <td>10</td>      <td>10</td>    </tr>    <tr>      <td>4. Build and Run DeepStream Pipeline</td>      <td>20</td>      <td>20</td>    </tr>    <tr>      <td>5. Analyze the Results</td>      <td>1</td>      <td>10</td>    </tr>    <tr>      <td>BONUS. Visualize Frames</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table>\n",
        "\n",
        "<p><img src='images/iva_framework.png' width=600></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea28a7a-3536-4c75-8c84-5978f49db9a6",
      "metadata": {
        "id": "1ea28a7a-3536-4c75-8c84-5978f49db9a6"
      },
      "source": [
        "### Step 0: The Problem ###\n",
        "You are a developer for an automobile fleet management company. You have recently installed dashboard cameras on all of the vehicles and are ready to implement AI to analyze the fleet's driving behavior. One of the issues you've noticed with the fleet is [tailgating](https://en.wikipedia.org/wiki/Tailgating), which occurs when the vehicle drives behind another vehicle without leaving sufficient distance to stop without causing a collision if the vehicle in front stops suddenly. You've decied to build a DeepStream application that will help monitor this behavior. At this point, you want to be able to log occurences of tailgating so you can understand the frequency. Note that while the input video sources are static files, the pipeline can easily be modified to consume videos in real-time."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f1c9bd-488a-4b54-bbc0-80ab4ecd5c4e",
      "metadata": {
        "id": "14f1c9bd-488a-4b54-bbc0-80ab4ecd5c4e"
      },
      "source": [
        "**Instructions**: <br>\n",
        "0.1 Execute the cell to set the target video as an environment variable. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f79d8c-9bc3-4f2b-929b-3baab61cbd5c",
      "metadata": {
        "id": "b8f79d8c-9bc3-4f2b-929b-3baab61cbd5c"
      },
      "outputs": [],
      "source": [
        "# 0.1\n",
        "# DO NOT CHANGE THIS CELL\n",
        "import os\n",
        "os.environ['TARGET_VIDEO_PATH']='data/assessment_stream.h264'\n",
        "os.environ['TARGET_VIDEO_PATH_MP4']='data/assessment_stream.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d18bdd-6ee6-4241-aa2b-d057bd04309d",
      "metadata": {
        "id": "24d18bdd-6ee6-4241-aa2b-d057bd04309d"
      },
      "source": [
        "### Step 1: Understanding the Input Video ###\n",
        "The first step is to understand the properties of the input videos before we can design a system to digest them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42feee71-f5d3-4f15-a120-5aaf12724b70",
      "metadata": {
        "id": "42feee71-f5d3-4f15-a120-5aaf12724b70"
      },
      "source": [
        "Use the `ffprobe` ([see documentation if needed](https://ffmpeg.org/ffprobe.html)) command line utility to obtain the `height`, `width`, and `frame rate` of the input video. We're also using the `-hide_banner` option to minimize the text output.\n",
        "\n",
        "**Instructions**: <br>\n",
        "1.1 Execute the cell to preview the video. <br>\n",
        "1.2 Execute the cell to gather information from input video stream. <br>\n",
        "1.3 Modify the `<FIXME>`s _only_ to the correct values and execute the cell to mark your answer. _You can execute this cell multiple times until satisfactory_. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4976ef4-5a16-4106-8454-48c07cfad8d8",
      "metadata": {
        "id": "f4976ef4-5a16-4106-8454-48c07cfad8d8",
        "outputId": "9568ac67-8d6e-45fb-ee79-40a5e1a81537"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=\"data/assessment_stream.mp4\" controls  width=\"720\" >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1.1\n",
        "# DO NOT CHANGE THIS CELL\n",
        "from IPython.display import Video\n",
        "Video(os.environ['TARGET_VIDEO_PATH_MP4'], width=720)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83672ee2-3e0f-47b1-bac3-f22df24669e9",
      "metadata": {
        "tags": [],
        "id": "83672ee2-3e0f-47b1-bac3-f22df24669e9",
        "outputId": "69a16975-4da6-458c-f3bd-aecc749958dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input #0, h264, from 'data/assessment_stream.h264':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "    Stream #0:0: Video: h264 (High), yuv420p(progressive), 1280x720, 59.94 fps, 59.94 tbr, 1200k tbn, 119.88 tbc\n"
          ]
        }
      ],
      "source": [
        "# 1.2\n",
        "# DO NOT CHANGE THIS CELL\n",
        "!ffprobe -i $TARGET_VIDEO_PATH \\\n",
        "         -hide_banner \\\n",
        "         2>&1| tee my_assessment/video_profile.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368d5c7b-7798-4920-800f-608d3752d2ab",
      "metadata": {
        "id": "368d5c7b-7798-4920-800f-608d3752d2ab"
      },
      "outputs": [],
      "source": [
        "# 1.3\n",
        "FRAME_RATE=60\n",
        "FRAME_HEIGHT=720\n",
        "FRAME_WIDTH=1280\n",
        "FRAME_CODEC='h264'\n",
        "FRAME_COLOR_FORMAT='yuv'\n",
        "\n",
        "# DO NOT CHANGE BELOW\n",
        "Answer=f\"\"\"\\\n",
        "FRAME RATE: {round(FRAME_RATE)} FPS \\\n",
        "HEIGHT: {FRAME_HEIGHT} \\\n",
        "WIDTH: {FRAME_WIDTH} \\\n",
        "FRAME_CODEC: {FRAME_CODEC} \\\n",
        "FRAME_COLOR_FORMAT: {FRAME_COLOR_FORMAT} \\\n",
        "\"\"\"\n",
        "\n",
        "!echo $Answer > my_assessment/answer_1.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1998b0e1-2bb8-4922-af6a-710f2e47f9df",
      "metadata": {
        "id": "1998b0e1-2bb8-4922-af6a-710f2e47f9df"
      },
      "source": [
        "### Step 2: Brainstorm AI Inference and Download a Pre-Trained Model ###\n",
        "The next step is to brain storm the AI inference needed to achieve the objective. For this application, we need to detect cars in the frame and identify cases when the bounding box crosses below a threshold (illustrated below).\n",
        "\n",
        "<p><img src='images/tailgating_logic.png' width=720></p>\n",
        "\n",
        "Fortunately, there is a [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/dashcamnet) purpose-built object detection model that has been trained on similar data as our video. We can use the [NGC CLI](https://ngc.nvidia.com/setup/installers/cli) to download the [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/dashcamnet) model for our application"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56ba02d6-91d7-467a-8063-4b161beda2cf",
      "metadata": {
        "id": "56ba02d6-91d7-467a-8063-4b161beda2cf"
      },
      "source": [
        "**Instructions**: <br>\n",
        "2.1 Execute the cell to install the NGC CLI. <br>\n",
        "2.2 Execute the cell to use the `ngc registry mode list` command that lists all available models. We use the `--column name`, `--column repository`, and `--column application` options to display only the relevant columns. Afterwards, review the model card for [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/dashcamnet) and confirm that the model is fit for purpose. <br>\n",
        "2.3 Update the `<FIXME>`s _only_ and execute the cell to download the [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/dashcamnet) model. The output of the command will generate a text file for grading purposes. _You can execute this cell multiple times until satisfactory_. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f0c649-280e-4ad9-a45f-4125c36afa13",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "37f0c649-280e-4ad9-a45f-4125c36afa13",
        "outputId": "e0a5d1fa-c562-408b-848e-e32133877307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /dli/task/ngc_assets/ngccli/ngccli_linux.zip\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/pycares/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/pycares/_cares.abi3.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/entry_points.txt  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_grpc-1.29.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libk5crypto.so.3  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt/_wrappers.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/licenses/LICENSE.BSD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/licenses/LICENSE.APACHE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-44.0.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/propcache/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/propcache/_helpers_c.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_ssl.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_csv.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_queue.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_multibytecodec.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/select.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_bisect.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_contextvars.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_datetime.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_kr.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha256.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_jp.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_cn.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_hashlib.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_opcode.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_struct.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_posixshmem.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_json.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_decimal.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/array.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/zlib.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha512.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_statistics.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/binascii.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_hk.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/resource.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/math.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/pyexpat.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_heapq.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_random.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/fcntl.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_posixsubprocess.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_elementtree.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha3.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_md5.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_multiprocessing.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_tw.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_blake2.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_socket.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/unicodedata.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_iso2022.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/mmap.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha1.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/grp.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_pickle.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/termios.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/LICENSE  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-8.5.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_http_writer.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_http_parser.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_websocket/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_websocket/reader_c.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_websocket/mask.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/entry_points.txt  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_api-1.29.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libpython3.9.so.1.0  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkrb5.so.3  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkrb5support.so.0  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/LICENSE.BSD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/LICENSE.APACHE  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/packaging-24.2.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libffi.so.6  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/crypt/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/crypt/x86_64-linux-lib.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/_cffi_backend.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libz.so.1  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/LICENSE  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/typing_extensions-4.12.2.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/docker-7.1.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/main.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libcom_err.so.2  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/base_library.zip  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libcrypto.so.10  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/protobuf-5.29.1.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/grpcio-1.67.1.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/resources-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/s3.rst  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/cloudfront.rst  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/LICENSE.rst  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/Deprecated-1.2.15.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/attrs-24.3.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libfreebl3.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/cygrpc.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/roots.pem  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/yarl/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/yarl/_quoting_c.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/multidict/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/multidict/_multidict.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/googleapis_common_protos-1.66.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkeyutils.so.1  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/_psutil_linux.abi3.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/_psutil_posix.abi3.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libpcre.so.1  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_semantic_conventions-0.50b0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/wrapt-1.17.0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libselinux.so.1  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libssl.so.10  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_proto-1.29.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/charset_normalizer/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/charset_normalizer/md__mypyc.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/charset_normalizer/md.cpython-39-x86_64-linux-gnu.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/entry_points.txt  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_instrumentation-0.50b0.dist-info/INSTALLER  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libgcc_s.so.1  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/RECORD  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_exporter_otlp_proto_common-1.29.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/jaraco/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/jaraco/text/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jaraco/text/Lorem ipsum.txt  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/severity/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/severity/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/severity/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/severity/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/_internal/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/_internal/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/_internal/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_logs/_internal/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/__pycache__/contextvars_context.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/__pycache__/context.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/contextvars_context.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/context/context.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/export/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/export/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/_internal/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/_internal/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/_internal/export/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/_internal/export/in_memory_log_exporter.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_logs/_internal/export/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/sampling.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/id_generator.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/export/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/export/in_memory_span_exporter.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/trace/export/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/resources/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/resources/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/util/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/util/__init__.pyi  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/util/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/util/instrumentation.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/version/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/version/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/__init__.pyi  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/py.typed  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_configuration/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_configuration/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/error_handler/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/error_handler/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_events/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/_events/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/view/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/view/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/export/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/export/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/instrument.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/measurement_consumer.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/buckets.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/errors.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/exponent_mapping.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/logarithm_mapping.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.md  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/measurement.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exceptions.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/metric_reader_storage.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/point.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/_view_instrument_match.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/export/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/export/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/view.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/aggregation.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/sdk_configuration.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exemplar/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exemplar/exemplar_filter.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exemplar/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exemplar/exemplar.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/metrics/_internal/exemplar/exemplar_reservoir.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/environment_variables/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/sdk/environment_variables/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/status.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/__pycache__/span.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/__pycache__/status.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/span.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/__pycache__/tracecontext.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/tracecontext.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/trace/propagation/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/bootstrap_gen.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/auto_instrumentation/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/auto_instrumentation/_load.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/auto_instrumentation/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/auto_instrumentation/sitecustomize.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/utils.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/bootstrap.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/environment_variables.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/version.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/distro.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/sqlcommenter_utils.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/_semconv.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/propagators.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/dependencies.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/instrumentation/instrumentor.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/_importlib_metadata.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/re.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/_decorator.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/_providers.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/_once.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/re.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/types.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/__pycache__/_importlib_metadata.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/_providers.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/types.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/_once.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/util/_decorator.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/__pycache__/__init__.cpython-39.pyc  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/trace_pb2.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/trace_pb2.pyi  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/trace/v1/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/common_pb2.pyi  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/common/v1/common_pb2.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/logs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/logs/v1/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/logs/v1/logs_pb2.pyi  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/logs/v1/logs_pb2.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/version/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/version/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/version/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/version/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/__pycache__/__init__.cpython-39.pyc  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/trace_service_pb2_grpc.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/trace_service_pb2.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/trace/v1/trace_service_pb2.pyi  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/logs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/logs/v1/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/logs/v1/logs_service_pb2.pyi  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/logs/v1/logs_service_pb2.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/logs/v1/logs_service_pb2_grpc.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/metrics_service_pb2_grpc.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/metrics_service_pb2.pyi  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/collector/metrics/v1/metrics_service_pb2.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/py.typed  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/resource_pb2.pyi  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/resource/v1/resource_pb2.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/metrics_pb2.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/proto/metrics/v1/metrics_pb2.pyi  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/trace_encoder.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/version/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/version/__init__.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_log_encoder.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/metrics_encoder.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/metrics_encoder/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/metrics_encoder/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/_log_encoder/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/_log_encoder/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/trace_encoder/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/trace_encoder/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/common/_internal/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/_log_exporter/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/_log_exporter/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/metric_exporter/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/metric_exporter/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/version/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/version/__init__.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/exporter/otlp/proto/grpc/exporter.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/__pycache__/__init__.cpython-39.pyc  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/trace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/trace/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/trace/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/trace/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/schemas.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/version/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/version/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/version/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/version/__init__.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/py.typed  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/resource/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/resource/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/resource/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/resource/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/log_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/destination_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/host_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/db_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/test_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/gen_ai_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/telemetry_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/faas_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/event_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/cpu_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/net_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/webengine_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/geo_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/browser_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/disk_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/az_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/aws_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/file_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/linux_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/session_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/error_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/oci_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/dns_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/os_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/tls_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/code_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/message_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/thread_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/otel_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/opentracing_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/network_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/graphql_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/vcs_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/source_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/feature_flag_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/service_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/messaging_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/cloudfoundry_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/url_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/pool_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/user_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/cloudevents_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/enduser_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/k8s_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/profile_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/http_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/heroku_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/deployment_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/client_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/container_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/process_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/exception_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/cicd_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/rpc_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/user_agent_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/gcp_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/cloud_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/other_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/device_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/system_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/hw_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/peer_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/server_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/attributes/artifact_attributes.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/vcs_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/faas_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/db_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/system_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/hw_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/k8s_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/http_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/process_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/messaging_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/container_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/gen_ai_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/dns_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/_incubating/metrics/rpc_metrics.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/telemetry_attributes.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/error_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/otel_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/network_attributes.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/__init__.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/service_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/url_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/http_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/client_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/exception_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/user_agent_attributes.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/attributes/server_attributes.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/metrics/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/metrics/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/metrics/http_metrics.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/semconv/metrics/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/version/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/version/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/version/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/version/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/version/__init__.py  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/py.typed  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagate/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagate/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagate/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagate/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagate/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_events/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_events/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_events/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_events/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/_events/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/__pycache__/textmap.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/__pycache__/composite.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/composite.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/propagators/textmap.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/attributes/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/attributes/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/attributes/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/attributes/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/attributes/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/instrument.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/__pycache__/instrument.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/__pycache__/observation.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/observation.py  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/metrics/_internal/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/propagation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/propagation/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/propagation/__pycache__/__init__.cpython-39.pyc  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/baggage/propagation/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/environment_variables/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/environment_variables/__pycache__/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/environment_variables/__pycache__/__init__.cpython-39.pyc  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/environment_variables/py.typed  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry/environment_variables/__init__.py  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/_upb/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google/_upb/_message.abi3.so  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/METADATA  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/LICENSE  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/zipp-3.21.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/entry_points.txt  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/licenses/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/licenses/LICENSE  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/opentelemetry_sdk-1.29.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/_rust.abi3.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/ngc  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/COPYING  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/top_level.txt  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/RECORD  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/METADATA  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/WHEEL  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/INSTALLER  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/cacert.pem  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/service-2.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/b2bi/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/b2bi/2022-06-23/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/b2bi/2022-06-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/b2bi/2022-06-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/b2bi/2022-06-23/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/repostspace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/repostspace/2022-05-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/repostspace/2022-05-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/repostspace/2022-05-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/repostspace/2022-05-13/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dsql/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partnercentral-selling/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partnercentral-selling/2022-07-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partnercentral-selling/2022-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partnercentral-selling/2022-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partnercentral-selling/2022-07-26/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/2020-07-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/2020-07-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/2020-07-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/2020-07-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-web/2020-07-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.sdk-extras.json  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/2022-02-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/2022-02-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/2022-02-03/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/2022-02-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography-data/2022-02-03/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation/2023-07-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation/2023-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation/2023-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation/2023-07-26/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifyuibuilder/2021-08-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-user-subscriptions/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-user-subscriptions/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-user-subscriptions/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-user-subscriptions/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-user-subscriptions/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/examples-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/endpoints.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chatbot/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chatbot/2017-10-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chatbot/2017-10-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chatbot/2017-10-11/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chatbot/2017-10-11/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/2023-05-04/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/2023-05-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/2023-05-04/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/2023-05-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain-query/2023-05-04/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53profiles/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53profiles/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53profiles/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53profiles/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53profiles/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/2024-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/2024-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/2024-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/2024-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/invoicing/2024-12-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-sap/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-sap/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-sap/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-sap/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-sap/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.sdk-extras.json  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/tnb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/tnb/2008-10-21/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/tnb/2008-10-21/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/tnb/2008-10-21/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/tnb/2008-10-21/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-security/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-security/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-security/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-security/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-security/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/supplychain/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/supplychain/2024-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/supplychain/2024-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/supplychain/2024-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/supplychain/2024-01-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-serverless/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-serverless/2021-07-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-serverless/2021-07-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-serverless/2021-07-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-serverless/2021-07-13/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector-scan/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector-scan/2023-08-08/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector-scan/2023-08-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector-scan/2023-08-08/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector-scan/2023-08-08/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-reporting/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cost-optimization-hub/2022-07-26/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/arc-zonal-shift/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/arc-zonal-shift/2022-10-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/arc-zonal-shift/2022-10-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/arc-zonal-shift/2022-10-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/arc-zonal-shift/2022-10-30/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/2023-11-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/2023-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/2023-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/2023-11-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qapps/2023-11-27/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.sdk-extras.json  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/2023-02-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/2023-02-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/2023-02-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/2023-02-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pcs/2023-02-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/privatenetworks/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/privatenetworks/2021-12-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/privatenetworks/2021-12-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/privatenetworks/2021-12-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/privatenetworks/2021-12-03/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/scheduler/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/scheduler/2021-06-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/scheduler/2021-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/scheduler/2021-06-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/scheduler/2021-06-30/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/2022-07-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/2022-07-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/2022-07-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/2022-07-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-explorer-2/2022-07-28/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/m2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/m2/2021-04-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/m2/2021-04-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/m2/2021-04-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/m2/2021-04-28/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/2023-05-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/2023-05-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/2023-05-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/2023-05-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds-data/2023-05-31/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearchserverless/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearchserverless/2021-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearchserverless/2021-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearchserverless/2021-11-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearchserverless/2021-11-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/2022-02-17/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/2022-02-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/2022-02-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/2022-02-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanrooms/2022-02-17/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/2022-09-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/2022-09-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/2022-09-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/2022-09-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecatalyst/2022-09-28/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medical-imaging/2023-07-19/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/2024-04-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/2024-04-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/2024-04-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/2024-04-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-signals/2024-04-15/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/2021-06-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/2021-06-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/2021-06-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/2021-06-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rbin/2021-06-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/keyspaces/2022-02-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/trustedadvisor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/trustedadvisor/2022-09-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/trustedadvisor/2022-09-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/trustedadvisor/2022-09-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/trustedadvisor/2022-09-15/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/2021-10-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/2021-10-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/2021-10-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/2021-10-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migration-hub-refactor-spaces/2021-10-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/taxsettings/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/taxsettings/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/taxsettings/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/taxsettings/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/taxsettings/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/osis/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/osis/2022-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/osis/2022-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/osis/2022-01-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/osis/2022-01-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/2021-06-17/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/2021-06-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/2021-06-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/2021-06-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleetwise/2021-06-17/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/artifact/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notificationscontacts/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-agreement/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-agreement/2020-03-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-agreement/2020-03-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-agreement/2020-03-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-agreement/2020-03-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mailmanager/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mailmanager/2023-10-17/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mailmanager/2023-10-17/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mailmanager/2023-10-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mailmanager/2023-10-17/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/oam/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/oam/2022-06-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/oam/2022-06-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/oam/2022-06-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/oam/2022-06-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-serverless/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-serverless/2021-04-21/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-serverless/2021-04-21/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-serverless/2021-04-21/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-serverless/2021-04-21/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/freetier/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/freetier/2023-09-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/freetier/2023-09-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/freetier/2023-09-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/freetier/2023-09-07/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/2023-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/2023-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/2023-08-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/2023-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmonitor/2023-08-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-maps/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-maps/2020-11-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-maps/2020-11-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-maps/2020-11-19/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-maps/2020-11-19/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/2021-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/2021-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/2021-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/2021-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/verifiedpermissions/2021-12-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/simspaceweaver/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/simspaceweaver/2022-10-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/simspaceweaver/2022-10-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/simspaceweaver/2022-10-28/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/simspaceweaver/2022-10-28/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/2023-11-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/2023-11-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/2023-11-29/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/2023-11-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune-graph/2023-11-29/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/2023-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/2023-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/2023-09-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/2023-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-runtime/2023-09-30/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/security-ir/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/notifications/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/2022-12-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/2022-12-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/2022-12-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/2022-12-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apptest/2022-12-06/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billingconductor/2021-07-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/2015-10-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/2015-10-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/2015-10-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/2015-10-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pipes/2015-10-07/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securitylake/2018-05-10/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail-data/2021-08-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail-data/2021-08-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail-data/2021-08-11/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail-data/2021-08-11/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/2021-08-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/2021-08-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/2021-08-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/2021-08-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhuborchestrator/2021-08-28/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcases/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcases/2022-10-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcases/2022-10-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcases/2022-10-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcases/2022-10-03/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/observabilityadmin/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/2022-11-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/2022-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/2022-11-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/2022-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/omics/2022-11-28/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/_retry.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/2021-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/2021-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/2021-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/2021-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup-gateway/2021-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rolesanywhere/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rolesanywhere/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rolesanywhere/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rolesanywhere/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rolesanywhere/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/2023-09-06/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/2023-09-06/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/2023-09-06/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/2023-09-06/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cleanroomsml/2023-09-06/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/2021-06-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/2021-06-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/2021-06-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/2021-06-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/internetmonitor/2021-06-03/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.sdk-extras.json  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-ad/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-ad/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-ad/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-ad/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-ad/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/socialmessaging/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/socialmessaging/2024-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/socialmessaging/2024-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/socialmessaging/2024-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/socialmessaging/2024-01-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/2023-07-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/2023-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/2023-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/2023-07-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent-runtime/2023-07-26/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation-runtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation-runtime/2024-06-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation-runtime/2024-06-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation-runtime/2024-06-13/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-data-automation-runtime/2024-06-13/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/2023-05-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/2023-05-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/2023-05-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/2023-05-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appfabric/2023-05-19/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-webrtc-storage/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-webrtc-storage/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-webrtc-storage/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-webrtc-storage/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-webrtc-storage/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-thin-client/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-thin-client/2023-08-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-thin-client/2023-08-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-thin-client/2023-08-22/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces-thin-client/2023-08-22/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector2/2020-06-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/2018-05-10/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datazone/2018-05-10/paginators-1.sdk-extras.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront-keyvaluestore/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront-keyvaluestore/2022-07-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront-keyvaluestore/2022-07-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront-keyvaluestore/2022-07-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront-keyvaluestore/2022-07-26/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivschat/2020-07-14/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeconnections/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeconnections/2023-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeconnections/2023-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeconnections/2023-12-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeconnections/2023-12-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qbusiness/2023-11-27/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-routes/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-routes/2020-11-19/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-routes/2020-11-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-routes/2020-11-19/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-routes/2020-11-19/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-geospatial/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-geospatial/2020-05-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-geospatial/2020-05-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-geospatial/2020-05-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-geospatial/2020-05-27/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-linux-subscriptions/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-linux-subscriptions/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-linux-subscriptions/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-linux-subscriptions/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager-linux-subscriptions/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaigns/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaigns/2021-01-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaigns/2021-01-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaigns/2021-01-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaigns/2021-01-30/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.sdk-extras.json  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-influxdb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-influxdb/2023-01-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-influxdb/2023-01-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-influxdb/2023-01-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-influxdb/2023-01-27/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-voice/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-voice/2022-08-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-voice/2022-08-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-voice/2022-08-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-voice/2022-08-03/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/entityresolution/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/entityresolution/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/entityresolution/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/entityresolution/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/entityresolution/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rum/2018-05-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb-elastic/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb-elastic/2022-11-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb-elastic/2022-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb-elastic/2022-11-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb-elastic/2022-11-28/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaignsv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaignsv2/2024-04-23/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaignsv2/2024-04-23/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaignsv2/2024-04-23/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectcampaignsv2/2024-04-23/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controltower/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controltower/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controltower/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controltower/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controltower/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent/2023-06-05/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent/2023-06-05/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent/2023-06-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock-agent/2023-06-05/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2011-12-05/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2011-12-05/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2011-12-05/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra-ranking/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra-ranking/2022-10-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra-ranking/2022-10-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra-ranking/2022-10-19/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra-ranking/2022-10-19/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pca-connector-scep/2018-05-10/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdk-default-configuration.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/2023-11-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/2023-11-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/2023-11-26/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/2023-11-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks-auth/2023-11-26/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-deployment/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-deployment/2023-01-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-deployment/2023-01-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-deployment/2023-01-25/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-deployment/2023-01-25/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/2020-07-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/2020-07-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/2020-07-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/2020-07-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs-realtime/2020-07-14/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-metrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-metrics/2022-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-metrics/2022-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-metrics/2022-09-30/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-metrics/2022-09-30/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qconnect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qconnect/2020-10-19/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qconnect/2020-10-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qconnect/2020-10-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qconnect/2020-10-19/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/2024-06-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/2024-06-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/2024-06-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/2024-06-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-pricing-calculator/2024-06-19/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backupsearch/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-data-exports/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-data-exports/2023-11-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-data-exports/2023-11-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-data-exports/2023-11-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bcm-data-exports/2023-11-26/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/2021-09-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/2021-09-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/2021-09-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/2021-09-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/payment-cryptography/2021-09-14/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/2020-02-26/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/2020-02-26/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/2020-02-26/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/2020-02-26/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/drs/2020-02-26/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/2023-09-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/2023-09-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/2023-09-07/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/2023-09-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/billing/2023-09-07/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/2022-12-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/2022-12-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/2022-12-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/2022-12-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackagev2/2022-12-25/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptunedata/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptunedata/2023-08-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptunedata/2023-08-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptunedata/2023-08-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptunedata/2023-08-01/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-quicksetup/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-quicksetup/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-quicksetup/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-quicksetup/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-quicksetup/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/vpc-lattice/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/vpc-lattice/2022-11-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/vpc-lattice/2022-11-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/vpc-lattice/2022-11-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/vpc-lattice/2022-11-30/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iottwinmaker/2021-11-29/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/endpoint-rule-set-1.json.gz  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice-v2/2022-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3tables/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-places/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-places/2020-11-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-places/2020-11-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-places/2020-11-19/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/geo-places/2020-11-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/partitions.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/2021-11-11/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/2021-11-11/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/2021-11-11/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/2021-11-11/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfigdata/2021-11-11/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/launch-wizard/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/launch-wizard/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/launch-wizard/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/launch-wizard/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/launch-wizard/2018-05-10/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-media-pipelines/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-media-pipelines/2021-07-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-media-pipelines/2021-07-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-media-pipelines/2021-07-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-media-pipelines/2021-07-15/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/waiters-2.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/deadline/2023-10-12/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/2018-05-10/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/2018-05-10/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/2018-05-10/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/2018-05-10/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/controlcatalog/2018-05-10/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support-app/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support-app/2021-08-20/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support-app/2021-08-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support-app/2021-08-20/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support-app/2021-08-20/paginators-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/2021-02-01/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/2021-02-01/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/2021-02-01/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/2021-02-01/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/evidently/2021-02-01/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/examples-1.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/paginators-1.sdk-extras.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkflowmonitor/2023-04-19/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/2023-04-20/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/2023-04-20/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/2023-04-20/endpoint-rule-set-1.json.gz  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/2023-04-20/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/bedrock/2023-04-20/waiters-2.json  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/\n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/\n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/service-2.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/endpoint-rule-set-1.json.gz  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/paginators-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/examples-1.json  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libgssapi_krb5.so.2  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/certifi/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/certifi/cacert.pem  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/certifi/py.typed  \n",
            "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/frozenlist/\n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/frozenlist/_frozenlist.cpython-39-x86_64-linux-gnu.so  \n",
            "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libstdc++.so.6  \n",
            " extracting: /dli/task/ngc_assets/ngccli/ngc-cli.md5  \n"
          ]
        }
      ],
      "source": [
        "# 2.1\n",
        "# DO NOT CHANGE THIS CELL\n",
        "import os\n",
        "os.environ['NGC_DIR']='/dli/task/ngc_assets'\n",
        "os.environ['CLI']='ngccli_linux.zip'\n",
        "\n",
        "# Remove previous versions of NGC CLI, copy, and install NGC CLI\n",
        "!rm -r $NGC_DIR/ngccli/*\n",
        "!cp /dli/task/$CLI $NGC_DIR/ngccli/$CLI\n",
        "!unzip -u \"$NGC_DIR/ngccli/$CLI\" \\\n",
        "       -d $NGC_DIR/ngccli/\n",
        "!rm $NGC_DIR/ngccli/*.zip\n",
        "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"NGC_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7bf605e-fe17-48a8-b1b6-70f594a83b43",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "d7bf605e-fe17-48a8-b1b6-70f594a83b43",
        "outputId": "bf97d128-c471-437a-8028-c06fe86b93f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\n",
            "    \"application\": \"OTHER\",\n",
            "    \"createdDate\": \"2022-12-08T23:33:07.209Z\",\n",
            "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
            "    \"displayName\": \"CitySemSegFormer\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"NSPECT-H5EZ-26RO\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_onnx_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 347161809,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"citysemsegformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:07:33.358Z\"\n",
            "},{\n",
            "    \"application\": \"Character Recognition\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.268Z\",\n",
            "    \"description\": \"Model to recognize characters from the image crop of a License Plate.\",\n",
            "    \"displayName\": \"License Plate Recognition\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Traffic\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Public Safety\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"NSPECT-VREL-WCW5\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"License Plate recognition\",\n",
            "                \"Computer Vision\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"OCR\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_onnx_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 115441532,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"lprnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:07:43.593Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-29T23:17:55.307Z\",\n",
            "    \"description\": \"Mandarin Citrinet ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Citrinet ASR Mandarin\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Mandarin\",\n",
            "                \"Citrinet\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 583781459,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_zh_cn_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:49.412Z\"\n",
            "},{\n",
            "    \"application\": \"Riva\",\n",
            "    \"createdDate\": \"2021-08-20T03:26:03.060Z\",\n",
            "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
            "    \"displayName\": \"Riva ASR English LM\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Finetuning\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 6244940310,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechtotext_english_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:51.432Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-07-14T16:49:16.658Z\",\n",
            "    \"description\": \"Pre-trained FAN weights trained on NVImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained FAN based NVImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"fan_large_hybrid_nvimagenet\",\n",
            "    \"latestVersionSizeInBytes\": 308027815,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_fan_classification_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.607Z\"\n",
            "},{\n",
            "    \"application\": \"Question Answering\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:58.595Z\",\n",
            "    \"description\": \"Question Answering Bert Large uncased model for extractive question answering on any provided content.\",\n",
            "    \"displayName\": \"Question Answering SQUAD2.0 Bert - Large\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"SQUAD2.0\",\n",
            "                \"NLP\",\n",
            "                \"BERT Large\",\n",
            "                \"Riva\",\n",
            "                \"Question Answering\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 438459496,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"questionanswering_squad_english_bertlarge\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:52.133Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-01-06T18:04:05.681Z\",\n",
            "    \"description\": \"English Conformer ASR model for en-US\",\n",
            "    \"displayName\": \"RIVA Conformer ASR English(en-US)\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"English\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"STT\",\n",
            "                \"Riva\",\n",
            "                \"Conformer\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v4.0\",\n",
            "    \"latestVersionSizeInBytes\": 486998256,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_en_us_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:56:35.679Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:10:03.721Z\",\n",
            "    \"description\": \"Model trained on COCO2017 to detect and classify objects.\",\n",
            "    \"displayName\": \"Deformable DETR\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"ddetr_gc_vit_tiny_deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 203925867,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_deformable_detr_coco\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-02-03T00:51:31.334Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:15:50.885Z\",\n",
            "    \"description\": \"Base Brazilian Portuguese 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Brazilian Portuguese LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1227687850,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_pt_br_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:59.713Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-01-06T17:17:07.715Z\",\n",
            "    \"description\": \"German Citrinet ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Citrinet ASR German\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"STT\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"German\",\n",
            "                \"Citrinet\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 566726189,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_de_de_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:50:59.914Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-12-06T22:01:11.030Z\",\n",
            "    \"description\": \"Pre-trained FasterViT weights trained on NVImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained FasterViT based NVImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable-fastervit-1-nvimagenet_op17\",\n",
            "    \"latestVersionSizeInBytes\": 214269178,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_fastervit_classification_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-12-12T06:16:44.709Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-12-15T21:13:54.118Z\",\n",
            "    \"description\": \"For each word in the input text, the model predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks\",\n",
            "    \"displayName\": \"RIVA Punctuation for Arabic\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 408497303,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_ar_ar_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:37.352Z\"\n",
            "},{\n",
            "    \"application\": \"6-DoF object pose estimation\",\n",
            "    \"createdDate\": \"2024-08-23T01:02:44.320Z\",\n",
            "    \"description\": \"6-DoF object pose estimation and tracking, providing the object pose and 3D bounding box\",\n",
            "    \"displayName\": \"FoundationPose\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"NSPECT-RQFW-RMJA\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 132068712,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"foundationpose\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:54:46.421Z\"\n",
            "},{\n",
            "    \"application\": \"OTHER\",\n",
            "    \"createdDate\": \"2021-08-24T21:13:00.968Z\",\n",
            "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
            "    \"displayName\": \"PeopleSemSegnet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"NSPECT-U6TM-G6WM\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_shuffleseg_unet_onnx_v1.0.1\",\n",
            "    \"latestVersionSizeInBytes\": 3911384,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplesemsegnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:07:58.524Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva EA\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-17T23:02:17.225Z\",\n",
            "    \"description\": \"Base Russian 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Russian LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Russian\",\n",
            "                \"Riva\",\n",
            "                \"Citrinet\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 1218584607,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_ru_ru_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:59:04.162Z\"\n",
            "},{\n",
            "    \"application\": \"Open vocabulary object detection & phrase detection\",\n",
            "    \"createdDate\": \"2024-08-23T01:03:26.357Z\",\n",
            "    \"description\": \"Open vocabulary multi-modal object detection model trained on commercial data.\",\n",
            "    \"displayName\": \"Grounding DINO\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"NSPECT-VXUV-MBLL\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"grounding_dino_swin_tiny_commercial_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 2070706754,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"grounding_dino\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:59:04.463Z\"\n",
            "},{\n",
            "    \"accessType\": \"LISTED\",\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2024-10-02T01:22:40.278Z\",\n",
            "    \"description\": \"Visual ChangeNet-Segmentation with Foundation Model Backbone on ChangeSim for indoor warehouse change detection.\",\n",
            "    \"displayName\": \"Visual ChangeNet-Seg with FM Backbone - ChangeSim\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"productNames\",\n",
            "            \"values\": [\n",
            "                \"nv-ai-enterprise\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"visual_changenet_dinov2_changesim_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 4085700188,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"visual_changenet_changesim\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"productNames\": [\n",
            "        \"n\",\n",
            "        \"v\",\n",
            "        \"-\",\n",
            "        \"a\",\n",
            "        \"i\",\n",
            "        \"-\",\n",
            "        \"e\",\n",
            "        \"n\",\n",
            "        \"t\",\n",
            "        \"e\",\n",
            "        \"r\",\n",
            "        \"p\",\n",
            "        \"r\",\n",
            "        \"i\",\n",
            "        \"s\",\n",
            "        \"e\"\n",
            "    ],\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-10-02T01:23:07.174Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-05T23:21:38.219Z\",\n",
            "    \"description\": \"Base Spanish grammar\",\n",
            "    \"displayName\": \"Riva ASR Spanish Inverse Normalization Grammar\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 4133083,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"FAR\",\n",
            "    \"name\": \"inverse_normalization_es_us\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:07.162Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-12-06T22:01:58.880Z\",\n",
            "    \"description\": \"Pre-trained FasterViT weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained FasterViT based ImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_fastervit_6_224_1k_op17\",\n",
            "    \"latestVersionSizeInBytes\": 19259102,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_fastervit_classification_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-12-12T06:16:44.759Z\"\n",
            "},{\n",
            "    \"application\": \"License Plate Detection\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.144Z\",\n",
            "    \"description\": \"Object Detection network to detect license plates in an image of a car.\",\n",
            "    \"displayName\": \"LPDNet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"NSPECT-2A4D-MPST\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_v2.2.1\",\n",
            "    \"latestVersionSizeInBytes\": 1783847,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"lpdnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:55:19.217Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection (People)\",\n",
            "    \"createdDate\": \"2024-08-23T01:02:55.426Z\",\n",
            "    \"description\": \"BEVFusion model to detect 3D objects from point cloud and RGB data.\",\n",
            "    \"displayName\": \"BEVFusion for 3D Object Detection\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"NSPECT-H9ZQ-S46Q\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"bevfusion_1.0\",\n",
            "    \"latestVersionSizeInBytes\": 487094270,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"bevfusion\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:54.928Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-05T23:21:15.510Z\",\n",
            "    \"description\": \"Base English grammar\",\n",
            "    \"displayName\": \"Riva ASR English Inverse Normalization Grammar\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0a\",\n",
            "    \"latestVersionSizeInBytes\": 2526035,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"FAR\",\n",
            "    \"name\": \"inverse_normalization_en_us\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:52.482Z\"\n",
            "},{\n",
            "    \"application\": \"Optical Character Detection\",\n",
            "    \"createdDate\": \"2023-06-23T17:45:17.802Z\",\n",
            "    \"description\": \"Network to detect characters in an image.\",\n",
            "    \"displayName\": \"Optical Character Detection\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"NSPECT-DK41-LFNF\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_onnx_v2.4\",\n",
            "    \"latestVersionSizeInBytes\": 35637431,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"ocdnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:56.639Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:25:26.362Z\",\n",
            "    \"description\": \"Riva multisepaker with IPA for G2P\",\n",
            "    \"displayName\": \"RIVA EnglishUS Fastpitch\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 90691286,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_en_us_fastpitch_ipa\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-04-04T19:34:01.987Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:47:11.139Z\",\n",
            "    \"description\": \"Spanish EMEA (es-ES) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Citrinet-1024 ASR Spanish EMEA\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 566728046,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_es_es_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:44.314Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-07-14T16:48:11.826Z\",\n",
            "    \"description\": \"Pre-trained GCViT weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained GCViT ImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"gcvit_large_imagenet22k_384\",\n",
            "    \"latestVersionSizeInBytes\": 864054197,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_gcvit_classification_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.681Z\"\n",
            "},{\n",
            "    \"application\": \"Industrial Inspection\",\n",
            "    \"createdDate\": \"2023-10-16T18:21:19.998Z\",\n",
            "    \"description\": \"Visual ChangeNet-Segmentation (Research-only)\",\n",
            "    \"displayName\": \"Visual ChangeNet Segmentation - (Research-only)\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Optical Inspection\",\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"NSPECT-RDEU-6EYG\",\n",
            "                \"Industrial Inspection\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"visual_changenet_levircd_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 140683061,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"visual_changenet_segmentation_levircd\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:58:51.944Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-06-16T16:02:29.388Z\",\n",
            "    \"description\": \"Hindi Citrinet ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Citrinet ASR Hindi (hi-IN) - ASR set 1.0\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 566726299,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_hi_in_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:58.799Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:14:15.811Z\",\n",
            "    \"description\": \"Model trained on COCO2017 to detect and classify objects.\",\n",
            "    \"displayName\": \"DINO\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"dino_fan_large_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1197490926,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_dino_coco\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-02-03T00:49:22.928Z\"\n",
            "},{\n",
            "    \"application\": \"Industrial Inspection\",\n",
            "    \"createdDate\": \"2023-10-16T18:24:29.582Z\",\n",
            "    \"description\": \"Visual ChangeNet - Segmentation\",\n",
            "    \"displayName\": \"Visual ChangeNet - Segmentation\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"NSPECT-VF46-55NJ\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
            "    \"latestVersionSizeInBytes\": 152891970,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"visual_changenet_segmentation_landsatscd\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:58:47.767Z\"\n",
            "},{\n",
            "    \"application\": \"Computer Vision\",\n",
            "    \"createdDate\": \"2024-07-23T18:19:16.948Z\",\n",
            "    \"description\": \"Language Instructed Temporal Assistant\",\n",
            "    \"displayName\": \"LITA\",\n",
            "    \"framework\": \"VIA\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"VIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"1.0\",\n",
            "    \"latestVersionSizeInBytes\": 0,\n",
            "    \"name\": \"lita\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-07-23T18:19:17.263Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2021-11-23T07:36:59.791Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained EfficientDet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"CV\",\n",
            "                \"Transfer Learning\",\n",
            "                \"Metropolis\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"AI\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Smart Infrastructure\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"efficientnet_b2\",\n",
            "    \"latestVersionSizeInBytes\": 64864720,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_efficientdet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:03:00.867Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2023-06-23T17:45:17.695Z\",\n",
            "    \"description\": \"Pretrained model to generate semantic segmentation labels.\",\n",
            "    \"displayName\": \"Mask Auto Label\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1117192469,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"mask_auto_label\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.120Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2023-07-14T17:18:35.694Z\",\n",
            "    \"description\": \"Pre-trained segformer models trained on CityScapes.\",\n",
            "    \"displayName\": \"Pre-trained Segformer - CityScapes\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_fan_tiny_hybrid_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 41465826,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_segformer_cityscapes\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.572Z\"\n",
            "},{\n",
            "    \"application\": \"Joint Intent And Slot Classification\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-08T04:38:25.037Z\",\n",
            "    \"description\": \"Intent and Slot classification of the queries for the misty bot with DistilBert model trained on weather, smalltalk and POI (places of interest) data.\",\n",
            "    \"displayName\": \"Joint Intent and Slot Classification DistilBert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Natural Language Processing\",\n",
            "                \"Intent and slot classification\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 266351975,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"intentslotclassification_misty_english_distilbert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:29.612Z\"\n",
            "},{\n",
            "    \"application\": \"Text to Speech\",\n",
            "    \"createdDate\": \"2021-08-25T15:59:16.226Z\",\n",
            "    \"description\": \"Universal waveform generator from mel-spectrograms.\",\n",
            "    \"displayName\": \"Speech Synthesis Waveglow\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Text to Speech\",\n",
            "                \"TTS\",\n",
            "                \"Riva\",\n",
            "                \"Waveglow\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 342214978,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_waveglow\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:56.788Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-10-17T06:59:57.578Z\",\n",
            "    \"description\": \"Base French grammar\",\n",
            "    \"displayName\": \"Riva ASR French Inverse Normalization Grammar\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 3003583,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"FAR\",\n",
            "    \"name\": \"inverse_normalization_fr_fr\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:59.741Z\"\n",
            "},{\n",
            "    \"application\": \"In-context object segmentation & detection\",\n",
            "    \"createdDate\": \"2024-08-23T01:06:48.094Z\",\n",
            "    \"description\": \"In-context segmentation model trained on commercial data.\",\n",
            "    \"displayName\": \"SegIC\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\",\n",
            "                \"NSPECT-Y965-BJPM\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"segic_deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1239941612,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"segic\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:25.282Z\"\n",
            "},{\n",
            "    \"application\": \"Punctuation and Capitalization\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-31T21:38:24.169Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"transfer learning\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"nlp\",\n",
            "                \"capitalization\",\n",
            "                \"inference\",\n",
            "                \"Natural Language Processing\",\n",
            "                \"riva\",\n",
            "                \"punctuation\",\n",
            "                \"Conversational AI\",\n",
            "                \"bert\",\n",
            "                \"finetuning\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 438282546,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_en_us_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:42.072Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-11-11T00:52:05.519Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for Brazilian Portuguese\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 670191824,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_pt_br_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:57.382Z\"\n",
            "},{\n",
            "    \"application\": \"Gaze Detection\",\n",
            "    \"createdDate\": \"2021-08-20T03:53:17.042Z\",\n",
            "    \"description\": \"Detect a persons eye gaze point of regard and gaze vector.\",\n",
            "    \"displayName\": \"Gaze Estimation\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"NSPECT-JU5Z-3CZE\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Eye gaze estimation\",\n",
            "                \"Robotics\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 18282352,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"gazenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-03-17T22:47:23.514Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-06-16T16:03:55.256Z\",\n",
            "    \"description\": \"Hindi Conformer ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Hindi - ASR set 2.0\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_2.0\",\n",
            "    \"latestVersionSizeInBytes\": 272188608,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_hi_in_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:07.267Z\"\n",
            "},{\n",
            "    \"application\": \"Punctuation and Capitalization\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-31T21:37:40.065Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for Spanish\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"transfer learning\",\n",
            "                \"spanish\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"inference\",\n",
            "                \"Natural Language Processing\",\n",
            "                \"bert\",\n",
            "                \"finetuning\",\n",
            "                \"nlp\",\n",
            "                \"capitalization\",\n",
            "                \"riva\",\n",
            "                \"punctuation\",\n",
            "                \"Conversational AI\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 670196415,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_es_us_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:07.135Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva EA\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-17T23:05:19.998Z\",\n",
            "    \"description\": \"Base Spanish 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Spanish LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Spanish\",\n",
            "                \"Citrinet\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 1067128899,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_es_us_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:44.395Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-07-15T07:42:58.910Z\",\n",
            "    \"description\": \"Base French 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR French LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"lm\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"riva\",\n",
            "                \"Conversational AI\",\n",
            "                \"language models\",\n",
            "                \"french\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 713086783,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_fr_fr_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:59:19.150Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T16:50:07.700Z\",\n",
            "    \"description\": \"Pre-trained DINO weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained DINO ImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"gcvit_large_imagenet22k_384\",\n",
            "    \"latestVersionSizeInBytes\": 864054197,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_dino_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.591Z\"\n",
            "},{\n",
            "    \"application\": \"CLASSIFICATION\",\n",
            "    \"createdDate\": \"2022-12-08T23:34:10.762Z\",\n",
            "    \"description\": \"Pretrained backbones for TAO Toolkit TF2 image classification\",\n",
            "    \"displayName\": \"TAO Pretrained Classification-TF2\",\n",
            "    \"framework\": \"TransferLearningToolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TransferLearningToolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"efficientnet_b0\",\n",
            "    \"latestVersionSizeInBytes\": 47819977,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"SAVED_MODEL\",\n",
            "    \"name\": \"pretrained_classification_tf2\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2022-12-08T23:40:30.534Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-01-06T18:12:16.343Z\",\n",
            "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
            "    \"displayName\": \"Riva ASR English(en-US) LM\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"LM\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Vertex AI Workbench\",\n",
            "                \"Vertex AI\",\n",
            "                \"Quick Deploy\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Google Cloud\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v4.1\",\n",
            "    \"latestVersionSizeInBytes\": 8605186199,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_en_us_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:14.576Z\"\n",
            "},{\n",
            "    \"application\": \"NLP\",\n",
            "    \"createdDate\": \"2022-05-12T22:50:14.594Z\",\n",
            "    \"description\": \"Intent and Slot classification of the queries for the misty bot with BERT model trained on weather, smalltalk and POI (places of interest) data.\",\n",
            "    \"displayName\": \"Joint Intent and Slot Classification Misty Bert\",\n",
            "    \"framework\": \"TransferLearningToolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Intent and Slot Classification\",\n",
            "                \"Natural Language Processing\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TransferLearningToolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 438931389,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"intentslotclassification_misty_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:35.313Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-07-14T16:46:08.991Z\",\n",
            "    \"description\": \"Pre-trained GcViT weights trained on NVImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained GCViT NVImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"gcvit_base_nvimagenet\",\n",
            "    \"latestVersionSizeInBytes\": 335124302,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_gcvit_classification_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.084Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:42:33.571Z\",\n",
            "    \"description\": \"Spanish EMEA (es-ES) Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Spanish EMEA\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"nvidia ai\",\n",
            "                \"riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 486998436,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_es_es_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:29.838Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-09-22T23:18:04.410Z\",\n",
            "    \"description\": \"HifiGAN is a neural vocoder model for text-to-speech applications. It is intended as the second part of a two-stage speech synthesis pipeline, with a mel-spectrogram generator such as FastPitch as the first stage.\",\n",
            "    \"displayName\": \"RIVA EnglishUS Hifigan\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 55759177,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_en_us_hifigan\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-04-04T19:14:53.786Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2021-08-16T15:53:38.516Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained Object Detection\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"yolo\",\n",
            "                \"tao\",\n",
            "                \"ssd\",\n",
            "                \"retinanet\",\n",
            "                \"dssd\",\n",
            "                \"resnet\",\n",
            "                \"Retail\",\n",
            "                \"industrial\",\n",
            "                \"cv\",\n",
            "                \"public safety\",\n",
            "                \"efficientnet\",\n",
            "                \"fasterrcnn\",\n",
            "                \"inspection\",\n",
            "                \"smart city\",\n",
            "                \"smart infrastructure\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
            "    \"latestVersionSizeInBytes\": 29955696,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_object_detection\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-05-03T07:26:31.058Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:44:55.128Z\",\n",
            "    \"description\": \"Japanese (ja-JP) Conformer ASR model trained on ASR set 3.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Japanese\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"nvidia ai\",\n",
            "                \"riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
            "    \"latestVersionSizeInBytes\": 474821833,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_ja_jp_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:19.940Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-06-15T03:16:57.901Z\",\n",
            "    \"description\": \"Rusian Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Russian - ASR set 1.0\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"russian\",\n",
            "                \"conformer\",\n",
            "                \"riva\",\n",
            "                \"Conversational AI\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 276748357,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_ru_ru_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:59.794Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva EA\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-17T23:00:07.376Z\",\n",
            "    \"description\": \"Base German 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR German LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"Riva\",\n",
            "                \"German\",\n",
            "                \"Citrinet\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 2006212953,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_de_de_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:07.182Z\"\n",
            "},{\n",
            "    \"application\": \"Gesture Classification\",\n",
            "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
            "    \"description\": \"Classify gestures from hand crop images.\",\n",
            "    \"displayName\": \"GestureNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"Gesture recognition\",\n",
            "                \"NSPECT-ZXJ9-36FL\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"Computer Vision\",\n",
            "                \"Robotics\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0.2\",\n",
            "    \"latestVersionSizeInBytes\": 46124320,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"gesturenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:01.712Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:14:57.156Z\",\n",
            "    \"description\": \"Brazilian Portuguese (pt-BR) Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Brazilian Portuguese\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 276039081,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_pt_br_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:12.611Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2022-12-08T15:52:56.110Z\",\n",
            "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
            "    \"displayName\": \"PeopleNet Transformer\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 187954813,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplenet_transformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:00:34.825Z\"\n",
            "},{\n",
            "    \"application\": \"Fiducial Landmarks\",\n",
            "    \"createdDate\": \"2021-08-19T02:21:06.371Z\",\n",
            "    \"description\": \"Detect fiducial keypoints from an image of a face.\",\n",
            "    \"displayName\": \"Facial Landmarks Estimation\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"Facial landmark estimation\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Robotics\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"NSPECT-O7BY-43C5\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
            "    \"latestVersionSizeInBytes\": 2351014,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"fpenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:08.302Z\"\n",
            "},{\n",
            "    \"application\": \"OTHER\",\n",
            "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
            "    \"description\": \"Detect body pose from an image.\",\n",
            "    \"displayName\": \"BodyPoseNet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"Body pose estimation\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"NSPECT-PNSL-LGBX\",\n",
            "                \"Robotics\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_onnx_v1.0.1\",\n",
            "    \"latestVersionSizeInBytes\": 67198961,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"bodyposenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:53:43.093Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-11-11T00:50:42.208Z\",\n",
            "    \"description\": \"For each word in the input text, the model: predicts a punctuation mark that should follow the word (if any).\",\n",
            "    \"displayName\": \"RIVA Punctuation\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 620146438,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_ja_jp_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T14:52:36.417Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-11-11T00:51:28.529Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for Korean\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 436025233,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_ko_kr_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:30.140Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.235Z\",\n",
            "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
            "    \"displayName\": \"TrafficCamNet\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"NSPECT-YF0Y-6AVF\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Transfer Learning\",\n",
            "                \"CV\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"AI\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_onnx_v1.0.4\",\n",
            "    \"latestVersionSizeInBytes\": 5374617,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"trafficcamnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-07-17T00:13:50.504Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-01-06T17:15:39.660Z\",\n",
            "    \"description\": \"Spanish Citrinet ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Citrinet ASR Spanish\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"STT\",\n",
            "                \"Riva\",\n",
            "                \"Spanish\",\n",
            "                \"Citrinet\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 566726427,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_es_us_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:14.558Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:16:17.531Z\",\n",
            "    \"description\": \"Pre-trained EfficientNet backbone weights trained on NvImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained EfficientDet NvImageNet backbones\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"efficientnet-b0\",\n",
            "    \"latestVersionSizeInBytes\": 47819977,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_efficientdet_tf2_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-04-26T00:20:04.356Z\"\n",
            "},{\n",
            "    \"application\": \"Text to Speech\",\n",
            "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
            "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with LJSpeech voice.\",\n",
            "    \"displayName\": \"Speech Synthesis English FastPitch\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Text to Speech\",\n",
            "                \"English\",\n",
            "                \"TTS\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Fastpitch\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 82356302,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_english_fastpitch\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T14:52:51.530Z\"\n",
            "},{\n",
            "    \"accessType\": \"LISTED\",\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2024-10-02T01:22:37.429Z\",\n",
            "    \"description\": \"TAO Commercial Pretrained NV-Dinov2 Model ViT-G backbone\",\n",
            "    \"displayName\": \"TAO Commercial Pretrained NV-Dinov2 Model\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"productNames\",\n",
            "            \"values\": [\n",
            "                \"nv-ai-enterprise\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"nvdinov2_vitg\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"productNames\": [\n",
            "        \"n\",\n",
            "        \"v\",\n",
            "        \"-\",\n",
            "        \"a\",\n",
            "        \"i\",\n",
            "        \"-\",\n",
            "        \"e\",\n",
            "        \"n\",\n",
            "        \"t\",\n",
            "        \"e\",\n",
            "        \"r\",\n",
            "        \"p\",\n",
            "        \"r\",\n",
            "        \"i\",\n",
            "        \"s\",\n",
            "        \"e\"\n",
            "    ],\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-10-02T01:22:37.429Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:02:46.733Z\",\n",
            "    \"description\": \"Pre-trained DINO weights trained on NvImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained DINO NvImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"resnet50\",\n",
            "    \"latestVersionSizeInBytes\": 307117121,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_dino_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:39.960Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-07-15T09:06:14.477Z\",\n",
            "    \"description\": \"Base English 3-gram LM\",\n",
            "    \"displayName\": \"Riva ASR English(en-GB) LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"lm\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"riva\",\n",
            "                \"english\",\n",
            "                \"Conversational AI\",\n",
            "                \"en-gb\",\n",
            "                \"language models\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 582300065,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_en_gb_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:14.660Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-09-20T22:06:08.851Z\",\n",
            "    \"description\": \"FastPitch is a mel-spectrogram generator, designed to be used as the first part of a neural text-to-speech system in conjunction with a neural vocoder\",\n",
            "    \"displayName\": \"RIVA EnglishUS Fastpitch\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 90755625,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_en_us_fastpitch\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-04-04T19:55:54.319Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2023-07-14T16:52:34.232Z\",\n",
            "    \"description\": \"Pre-trained SegFormer weights trained on NvImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained SegFormer NvImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"fan_large_hybrid_nvimagenet\",\n",
            "    \"latestVersionSizeInBytes\": 308027815,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_segformer_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.141Z\"\n",
            "},{\n",
            "    \"application\": \"Pose Detection\",\n",
            "    \"createdDate\": \"2023-10-19T17:15:28.375Z\",\n",
            "    \"description\": \"3 pose detection model for retail objects.\",\n",
            "    \"displayName\": \"CenterPose - ISAAC Ros\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"NSPECT-KF0U-HJ1U\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_bottle_dla34\",\n",
            "    \"latestVersionSizeInBytes\": 79361021,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"centerpose_ros\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:54:24.837Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:04:34.889Z\",\n",
            "    \"description\": \"Pre-trained deformable_detr weights trained on NvImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained Deformable DETR NvImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"resnet50\",\n",
            "    \"latestVersionSizeInBytes\": 307117121,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_deformable_detr_nvimagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.677Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:21:46.866Z\",\n",
            "    \"description\": \"Base Korean 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Korean LM\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 743249224,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_ko_kr_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:34.637Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2021-10-22T18:24:05.069Z\",\n",
            "    \"description\": \"5 class action recognition network to recognize what people do in an image.\",\n",
            "    \"displayName\": \"Action Recognition Net\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_rgb_3d\",\n",
            "    \"latestVersionSizeInBytes\": 332020614,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"actionrecognitionnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-04-09T19:09:26.325Z\"\n",
            "},{\n",
            "    \"application\": \"Named Entity Recognition\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:57.311Z\",\n",
            "    \"description\": \"The model identifies a category/entity the word in the input text belongs to.\",\n",
            "    \"displayName\": \"Named Entity Recognition Bert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Named Entity Recognition\",\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"NER\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 440857990,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"namedentityrecognition_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:50:52.461Z\"\n",
            "},{\n",
            "    \"application\": \"Optical Character Recognition\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2023-06-23T17:45:17.804Z\",\n",
            "    \"description\": \"Model to recognise characters from a preceding OCDNet model.\",\n",
            "    \"displayName\": \"Optical Character Recognition\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"NSPECT-U6E7-WAPV\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.1.1\",\n",
            "    \"latestVersionSizeInBytes\": 46420752,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"ocrnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:07.085Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-07-21T21:47:01.676Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods, hyphens and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for French\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 670195137,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_fr_fr_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:19.847Z\"\n",
            "},{\n",
            "    \"application\": \"Classification\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.190Z\",\n",
            "    \"description\": \"Resnet18 model to classify a car crop into 1 out 6 car types.\",\n",
            "    \"displayName\": \"VehicleTypeNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Object Detection\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Traffic\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Public Safety\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"NSPECT-D097-A7LK\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Vehicle Classification\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_onnx_v1.1.0\",\n",
            "    \"latestVersionSizeInBytes\": 19895199,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"vehicletypenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:45.927Z\"\n",
            "},{\n",
            "    \"application\": \"Emotion Classification\",\n",
            "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
            "    \"description\": \"Network to classify emotions from face.\",\n",
            "    \"displayName\": \"EmotionNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"Computer Vision\",\n",
            "                \"NSPECT-1HSG-3OU3\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Emotion Recognition\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 4588024,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"emotionnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:07:53.527Z\"\n",
            "},{\n",
            "    \"application\": \"Optical Inspection\",\n",
            "    \"createdDate\": \"2023-07-14T17:37:01.024Z\",\n",
            "    \"description\": \"Model to classify defects in soldered components on a Printed Circuit Board.\",\n",
            "    \"displayName\": \"PCB Defect Classification\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 162510971,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pcb_classification\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:44:13.287Z\"\n",
            "},{\n",
            "    \"application\": \"Image Classification\",\n",
            "    \"createdDate\": \"2023-07-14T16:47:15.753Z\",\n",
            "    \"description\": \"Pre-trained FAN weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained FAN based ImageNet Classification weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"fan_hybrid_Xlarge_in22k\",\n",
            "    \"latestVersionSizeInBytes\": 538206697,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_fan_classification_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:40.628Z\"\n",
            "},{\n",
            "    \"application\": \"Pose Classification\",\n",
            "    \"createdDate\": \"2022-05-12T22:31:11.382Z\",\n",
            "    \"description\": \"Pose classification network to classify poses of people from their skeletons.\",\n",
            "    \"displayName\": \"Pose Classification\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-T13H-IX15\",\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_onnx_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 12730308,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"poseclassificationnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:03.412Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2025-07-22T15:01:28.402Z\",\n",
            "    \"description\": \"4 class object detection model for traffic intersections.\",\n",
            "    \"displayName\": \"TrafficCamNet Transformer Lite\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-YF0Y-6AVF\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 512002293,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"trafficcamnet_transformer_lite\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-07-22T15:01:38.737Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-07-21T20:09:28.480Z\",\n",
            "    \"description\": \"For each word in the input text, the model predicts a punctuation mark that should follow the word (if any), the model supports commas, poornvirams, exclaimation marks and question marks.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for Hindi\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 882514166,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_hi_in_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T14:52:28.946Z\"\n",
            "},{\n",
            "    \"application\": \"Pose Estimation\",\n",
            "    \"createdDate\": \"2021-12-06T00:47:27.212Z\",\n",
            "    \"description\": \"3D human pose estimation network to predict 34 keypoints in 3D of a person in an image.\",\n",
            "    \"displayName\": \"BodyPose3DNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"CV\",\n",
            "                \"Transfer Learning\",\n",
            "                \"Metropolis\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"AI\",\n",
            "                \"DL\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Computer Vision\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_performance_onnx_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 40360395,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"bodypose3dnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-09-20T00:53:59.443Z\"\n",
            "},{\n",
            "    \"application\": \"Instance Segmentation\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.177Z\",\n",
            "    \"description\": \"1 class instance segmentation network to detect and segment instances of people in an image.\",\n",
            "    \"displayName\": \"PeopleSegNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"AI\",\n",
            "                \"NSPECT-G9P3-PL45\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0.2\",\n",
            "    \"latestVersionSizeInBytes\": 73969636,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplesegnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:17.520Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-10-16T18:30:50.133Z\",\n",
            "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
            "    \"displayName\": \"PeopleNet - AMR\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Industrial Inspection\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 82594455,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplenet_amr\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:00:32.643Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2023-07-14T16:51:01.514Z\",\n",
            "    \"description\": \"Pre-trained SegFormer weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained SegFormer ImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"fan_hybrid_tiny\",\n",
            "    \"latestVersionSizeInBytes\": 30032227,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_segformer_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-04-26T00:28:31.312Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2022-05-12T22:31:10.383Z\",\n",
            "    \"description\": \"Model to detect one or more objects from a LIDAR point cloud file and return 3D bounding boxes.\",\n",
            "    \"displayName\": \"PointPillarNet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"NSPECT-6X3U-U5R7\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 5572401,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pointpillarnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:07:48.284Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:09:05.061Z\",\n",
            "    \"description\": \"Brazilian Portuguese (pt-BR) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Citrinet-1024 ASR Brazilian Portuguese\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 268199570,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_pt_br_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:12.317Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2023-07-14T17:37:27.823Z\",\n",
            "    \"description\": \"Model to segment persons in an image.\",\n",
            "    \"displayName\": \"PeopleSemSegformer\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\",\n",
            "                \"NSPECT-0X5V-20XX\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 214468681,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplesemsegformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:11.838Z\"\n",
            "},{\n",
            "    \"application\": \"Speech To Text\",\n",
            "    \"createdDate\": \"2022-06-16T15:51:02.239Z\",\n",
            "    \"description\": \"Base Hindi 3-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Hindi LM\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"kenlm\",\n",
            "                \"riva\",\n",
            "                \"Conversational AI\",\n",
            "                \"language model\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v3.1\",\n",
            "    \"latestVersionSizeInBytes\": 3488009941,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"BINARY\",\n",
            "    \"name\": \"speechtotext_hi_in_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:59:11.513Z\"\n",
            "},{\n",
            "    \"application\": \"Re-Identification\",\n",
            "    \"createdDate\": \"2024-01-26T04:23:45.137Z\",\n",
            "    \"description\": \"SWIN Transformer based Re-Identification network to generate embeddings for identifying persons in different scenes.\",\n",
            "    \"displayName\": \"Re-Identification Transformer\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"swin_base_1024\",\n",
            "    \"latestVersionSizeInBytes\": 877403065,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"reidentificationnet_transformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-09-23T20:10:08.439Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2025-07-24T17:32:15.220Z\",\n",
            "    \"description\": \"TAO Pretrained Sparse4D with Resnet101 Backbone\",\n",
            "    \"displayName\": \"Sparse4D\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Multi-Camera Network\",\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"NSPECT-XT56-057L\",\n",
            "                \"Object Detection and Tracking in 3D\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"Mixed\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 945644803,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"sparse4d_rn101\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"Mixed\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-07-31T06:47:16.464Z\"\n",
            "},{\n",
            "    \"application\": \"ReIdentification\",\n",
            "    \"createdDate\": \"2022-12-08T23:32:19.492Z\",\n",
            "    \"description\": \"Re-Identification network to generate embeddings for identifying persons in different scenes.\",\n",
            "    \"displayName\": \"ReIdentificationNet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"NSPECT-CQBD-MZW9\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
            "    \"latestVersionSizeInBytes\": 96398132,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"reidentificationnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:26.659Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-05T23:21:53.250Z\",\n",
            "    \"description\": \"Base German grammar\",\n",
            "    \"displayName\": \"Riva ASR German Inverse Normalization Grammar\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 4128539,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"FAR\",\n",
            "    \"name\": \"inverse_normalization_de_de\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:59.847Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:28:35.155Z\",\n",
            "    \"description\": \"Riva multisepaker with IPA for G2P\",\n",
            "    \"displayName\": \"RIVA EnglishUS Hifigan\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 55759160,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_en_us_hifigan_ipa\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-04-04T19:47:20.640Z\"\n",
            "},{\n",
            "    \"application\": \"Industrial Inspection\",\n",
            "    \"createdDate\": \"2023-12-08T19:24:56.979Z\",\n",
            "    \"description\": \"Change segmentation model.\",\n",
            "    \"displayName\": \"Visual ChangeNet Segmentation - MvTEC\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Optical Inspection\",\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Industrial Inspection\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 651624255,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"visual_changenet_segmentation_mvtec\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-12-12T06:16:44.771Z\"\n",
            "},{\n",
            "    \"application\": \"Punctuation and Capitalization\",\n",
            "    \"createdDate\": \"2021-08-18T20:05:02.000Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"Punctuation and Capitalization Bert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Punctuation\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Capitalization\",\n",
            "                \"BERT\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 438472343,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"punctuationcapitalization_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:44.684Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2023-12-06T21:56:04.072Z\",\n",
            "    \"description\": \"Model to recognise characters from a preceding OCDNet model.\",\n",
            "    \"displayName\": \"TAO Toolkit ODISE 1.1\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ConvNext-L\",\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"COCO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Open Vocabulary Segmentation\",\n",
            "                \"Deep Learning\",\n",
            "                \"Zero-Shot Segmentation\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"NSPECT-E99B-1B8S\",\n",
            "                \"Instance Segmentation\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Semantic Segmentation\",\n",
            "                \"Panoptic Segmentation\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"odise_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1534219088,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"odise\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:31.361Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-20T17:44:38.494Z\",\n",
            "    \"description\": \"Spanish Conformer ASR model trained on ASR set 2.0.\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Spanish\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"tao\",\n",
            "                \"nvidia ai\",\n",
            "                \"conformer\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 486998134,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_es_us_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-12-11T04:08:22.894Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-07-15T12:35:14.960Z\",\n",
            "    \"description\": \"English (en-GB) Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR English\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"tao\",\n",
            "                \"nvidia ai\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 488593412,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_en_gb_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-13T10:06:44.036Z\"\n",
            "},{\n",
            "    \"application\": \"Classification\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:41.810Z\",\n",
            "    \"description\": \"Resnet18 model to classify a car crop into 1 out 20 car brands.\",\n",
            "    \"displayName\": \"VehicleMakeNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Traffic\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Public Safety\",\n",
            "                \"NSPECT-P5IV-UMDM\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Vehicle Classification\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_onnx_v1.1.0\",\n",
            "    \"latestVersionSizeInBytes\": 7408442,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"vehiclemakenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:40.602Z\"\n",
            "},{\n",
            "    \"application\": \"Speaker Diarization\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-12-01T22:41:04.317Z\",\n",
            "    \"description\": \"Embedding Extractor model used in Riva Speaker Diarization\",\n",
            "    \"displayName\": \"RIVA Diarizer Embedding Extractor\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"speaker diarization\",\n",
            "                \"riva\",\n",
            "                \"titanet\",\n",
            "                \"speaker recognition\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 37480408,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"diarizer_titanet_small\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:21.988Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2023-10-19T17:16:26.828Z\",\n",
            "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
            "    \"displayName\": \"PeopleSemSegNet AMR\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 3889509,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplesemsegnet_amr\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:02:15.279Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:41.786Z\",\n",
            "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
            "    \"displayName\": \"PeopleNet\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-ITZN-CAOK\",\n",
            "                \"DetectNet_v2 Architecture\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_quantized_decrypted_v2.3.4\",\n",
            "    \"latestVersionSizeInBytes\": 8805800,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-06-12T18:51:11.283Z\"\n",
            "},{\n",
            "    \"application\": \"HeartRateNet Estimation\",\n",
            "    \"createdDate\": \"2021-08-20T20:50:01.480Z\",\n",
            "    \"description\": \"Estimate heart-rate non-invasively from RGB facial videos.\",\n",
            "    \"displayName\": \"HeartRateNet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-FFKE-V5VI\",\n",
            "                \"Heart Rate estimation\",\n",
            "                \"DeepStream\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"Computer Vision\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 588677,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"heartratenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:35.303Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:19:33.161Z\",\n",
            "    \"description\": \"Korean (ko-KR) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Citrinet-1024 ASR Korean\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"AMP\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 213063789,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_ko_kr_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"AMP\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:04.872Z\"\n",
            "},{\n",
            "    \"application\": \"Question Answering\",\n",
            "    \"createdDate\": \"2021-08-18T20:05:00.928Z\",\n",
            "    \"description\": \"Question Answering Megatron uncased model for extractive question answering on any provided content.\",\n",
            "    \"displayName\": \"Question Answering SQUAD2.0 Megatron\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"SQUAD2.0\",\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Question Answering\",\n",
            "                \"Megatron\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1337603607,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"questionanswering_squad_english_megatron\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:44.093Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-05T23:22:07.127Z\",\n",
            "    \"description\": \"Base English grammar\",\n",
            "    \"displayName\": \"Riva TTS English Normalization Grammar\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
            "    \"latestVersionSizeInBytes\": 2390007,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"FAR\",\n",
            "    \"name\": \"normalization_en_us\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2022-05-20T15:16:58.353Z\"\n",
            "},{\n",
            "    \"application\": \"Point Cloud - Object Detection\",\n",
            "    \"createdDate\": \"2023-12-08T19:26:40.220Z\",\n",
            "    \"description\": \"Transfusion model to detect 3D objects from pointcloud and RGB data.\",\n",
            "    \"displayName\": \"Transfusion for 3D Object Detection\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Optical Inspection\",\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Industrial Inspection\",\n",
            "                \"Computer Vision\",\n",
            "                \"NSPECT-K61X-1669\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 445702016,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"transfusion\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:09:35.782Z\"\n",
            "},{\n",
            "    \"application\": \"Punctuation and Capitalization\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-31T21:36:59.700Z\",\n",
            "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
            "    \"displayName\": \"RIVA Punctuation and Capitalization for German\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"german\",\n",
            "                \"transfer learning\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"inference\",\n",
            "                \"Natural Language Processing\",\n",
            "                \"bert\",\n",
            "                \"finetuning\",\n",
            "                \"nlp\",\n",
            "                \"capitalization\",\n",
            "                \"riva\",\n",
            "                \"punctuation\",\n",
            "                \"Conversational AI\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 712286911,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_de_de_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:36.974Z\"\n",
            "},{\n",
            "    \"application\": \"Joint Intent and Slot classification\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:58.439Z\",\n",
            "    \"description\": \"Intent and Slot classification of the qeuries for the weather chat bot (trained on weather chat bot data).\",\n",
            "    \"displayName\": \"Joint Intent and Slot Classification Bert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Intent and Slot Classification\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 443298808,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"intentslotclassification_weather_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:22.181Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-11-11T00:49:53.002Z\",\n",
            "    \"description\": \"For each word in the input text, the model: predicts a punctuation mark that should follow the word (if any).\",\n",
            "    \"displayName\": \"RIVA Punctuation\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 670187898,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"punctuationcapitalization_it_it_bert_base\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:05.231Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:41.798Z\",\n",
            "    \"description\": \"1 class object detection network to detect faces in an image.\",\n",
            "    \"displayName\": \"FaceDetectIR\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Object Detection\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Public Safety\",\n",
            "                \"IR\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Retail\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"NSPECT-1DBQ-GZ4A\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"DetectNet_v2\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
            "    \"latestVersionSizeInBytes\": 9532530,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"facedetectir\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T18:00:01.235Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:18:02.285Z\",\n",
            "    \"description\": \"Pre-trained EfficientDet models trained on COCO to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained EfficientDet Model trained on COCO\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"efficientdet-d0_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 43761906,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_efficientdet_tf2_coco\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-04-23T19:43:27.239Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:57.753Z\",\n",
            "    \"description\": \"Speech to Text Citrinet models for English.\",\n",
            "    \"displayName\": \"Speech to Text English Citrinet\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"English\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"STT\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Citrinet\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v3.0\",\n",
            "    \"latestVersionSizeInBytes\": 566724116,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"speechtotext_english_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:56:28.290Z\"\n",
            "},{\n",
            "    \"application\": \"Recognition\",\n",
            "    \"createdDate\": \"2022-12-09T04:16:26.343Z\",\n",
            "    \"description\": \"Embedding generator model to recognize objects on a checkout counter.\",\n",
            "    \"displayName\": \"Retail Object Recognition\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_head_fan_base_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 4608061,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"retail_object_recognition\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-03-13T23:48:29.380Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"createdDate\": \"2021-08-16T16:34:42.315Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using Transfer Learning Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained Semantic Segmentation\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Industrial\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Inspection\",\n",
            "                \"Public Safety\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Robotics\",\n",
            "                \"UNet\",\n",
            "                \"Retail\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Semantic Segmentation\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"vgg19\",\n",
            "    \"latestVersionSizeInBytes\": 540114376,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_semantic_segmentation\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:03:05.495Z\"\n",
            "},{\n",
            "    \"application\": \"Industrial Inspection\",\n",
            "    \"createdDate\": \"2023-10-16T18:06:06.309Z\",\n",
            "    \"description\": \"Visual ChangeNet - Classification Models\",\n",
            "    \"displayName\": \"Visual ChangeNet Classification\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Optical Inspection\",\n",
            "                \"TAO\",\n",
            "                \"CV\",\n",
            "                \"NSPECT-6WYF-WMQW\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Industrial Inspection\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"visual_changenet_nvpcb_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 283239529,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"visual_changenet_classification\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:58:41.170Z\"\n",
            "},{\n",
            "    \"application\": \"Semantic Segmentation\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2023-07-27T17:53:55.497Z\",\n",
            "    \"description\": \"Pretrained model to facilitate transfer learning for MAL on TAO Toolkit\",\n",
            "    \"displayName\": \"Pretrained Mask Auto Label\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"vit-base\",\n",
            "    \"latestVersionSizeInBytes\": 953005984,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"pth\",\n",
            "    \"name\": \"pretrained_mask_auto_label\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-07-27T17:55:46.389Z\"\n",
            "},{\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2025-07-17T00:13:32.839Z\",\n",
            "    \"description\": \"Pretrained ConvNextv2 backbone models to facilitate transfer learning for commercially viable models.\",\n",
            "    \"displayName\": \"Pretrained ConvNeXtV2\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-K2O1-WCT9\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"convnextv2_large_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 2375949465,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_convnextv2\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-07-17T00:13:47.592Z\"\n",
            "},{\n",
            "    \"application\": \"Text to Speech\",\n",
            "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
            "    \"description\": \"GAN-based waveform generator from mel-spectrograms.\",\n",
            "    \"displayName\": \"Speech Synthesis HiFi-GAN\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"tts\",\n",
            "                \"hifigan\",\n",
            "                \"riva\",\n",
            "                \"text to speech\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 51892640,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechsynthesis_hifigan\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:37.642Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"createdDate\": \"2022-03-23T11:50:58.191Z\",\n",
            "    \"description\": \"German Conformer ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR German\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"German\",\n",
            "                \"Conformer\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 488591508,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechtotext_de_de_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:56:06.157Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:45:51.824Z\",\n",
            "    \"description\": \"Italian (it-IT) Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Italian\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 488592459,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_it_it_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:51:36.969Z\"\n",
            "},{\n",
            "    \"application\": \"Instance segmentation\",\n",
            "    \"createdDate\": \"2024-08-24T18:29:15.761Z\",\n",
            "    \"description\": \"Binary instance segmentation model trained on COCO data.\",\n",
            "    \"displayName\": \"Mask2Former\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"NSPECT-0O3I-K8ZU\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"mask2former_swint_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 569718089,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"mask2former\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:59:09.444Z\"\n",
            "},{\n",
            "    \"application\": \"Pose Detection\",\n",
            "    \"createdDate\": \"2023-12-08T19:23:30.610Z\",\n",
            "    \"description\": \"3 pose detection model for retail objects.\",\n",
            "    \"displayName\": \"CenterPose\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"NSPECT-9H85-X0PJ\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_fan_small\",\n",
            "    \"latestVersionSizeInBytes\": 343890379,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"centerpose\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:54:14.064Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-12-06T21:58:15.346Z\",\n",
            "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
            "    \"displayName\": \"PeopleNet Transformer v2.0\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 214935774,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"peoplenet_transformer_v2\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-02-03T00:52:58.647Z\"\n",
            "},{\n",
            "    \"application\": \"Optical Inspection\",\n",
            "    \"createdDate\": \"2023-06-23T17:45:18.070Z\",\n",
            "    \"description\": \"Model to detect defects in soldered components on a Printed Circuit Board.\",\n",
            "    \"displayName\": \"Optical Inspection\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1075212308,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"optical_inspection\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:44:13.320Z\"\n",
            "},{\n",
            "    \"application\": \"Retail Object Detection\",\n",
            "    \"createdDate\": \"2022-12-08T23:34:26.149Z\",\n",
            "    \"description\": \"DINO (DETR with Improved DeNoising Anchor Boxes) based object detection network to detect retail objects on a checkout counter.\",\n",
            "    \"displayName\": \"Retail Object Detection\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"TAO\",\n",
            "                \"Transfer Learning\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_retail_object_detection_binary_v2.2.2.3\",\n",
            "    \"latestVersionSizeInBytes\": 314107341,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"retail_object_detection\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:03:46.262Z\"\n",
            "},{\n",
            "    \"application\": \"Speech To Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-05T23:25:16.549Z\",\n",
            "    \"description\": \"Base Mandarin 4-gram LM\",\n",
            "    \"displayName\": \"Riva ASR Mandarin LM\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"mandarin\",\n",
            "                \"lm\",\n",
            "                \"asr\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"riva\",\n",
            "                \"Conversational AI\",\n",
            "                \"language models\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"NA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 8461503449,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"arpa\",\n",
            "    \"name\": \"speechtotext_zh_cn_lm\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"NA\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:27.953Z\"\n",
            "},{\n",
            "    \"application\": \"Instance Segmentation\",\n",
            "    \"createdDate\": \"2021-08-16T16:34:42.327Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained Instance Segmentation\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"MaskRCNN\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"Instance Segmentation\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Inspection\",\n",
            "                \"Public Safety\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Robotics\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"resnet10\",\n",
            "    \"latestVersionSizeInBytes\": 40175904,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_instance_segmentation\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:03:03.219Z\"\n",
            "},{\n",
            "    \"application\": \"OBJECT_DETECTION\",\n",
            "    \"createdDate\": \"2022-12-08T23:33:54.449Z\",\n",
            "    \"description\": \"Pretrained efficientnet backbones for TAO Toolkit's efficientdet-tf2\",\n",
            "    \"displayName\": \"TAO Pretrained EfficientDet-TF2\",\n",
            "    \"framework\": \"TransferLearningToolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TransferLearningToolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"efficientnet_b0\",\n",
            "    \"latestVersionSizeInBytes\": 47819977,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"SAVED_MODEL\",\n",
            "    \"name\": \"pretrained_efficientdet_tf2\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2022-12-13T20:55:12.875Z\"\n",
            "},{\n",
            "    \"application\": \"Computer Vision\",\n",
            "    \"createdDate\": \"2024-07-25T04:14:09.933Z\",\n",
            "    \"description\": \"VITA Visual Language Model\",\n",
            "    \"displayName\": \"VITA\",\n",
            "    \"framework\": \"VIA\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"VIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"2.0.1\",\n",
            "    \"latestVersionSizeInBytes\": 17856811998,\n",
            "    \"name\": \"vita\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-07-25T06:40:35.088Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2023-07-14T17:00:31.919Z\",\n",
            "    \"description\": \"Pre-trained deformable_detr weights trained on ImageNet to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"Pre-trained Deformable DETR ImageNet weights\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Smart City\",\n",
            "                \"Transfer Learning\",\n",
            "                \"TAO\",\n",
            "                \"AI\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Deep Learning\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Transfer Learning Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"TLT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"gcvit_base_imagenet1k\",\n",
            "    \"latestVersionSizeInBytes\": 367540965,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_deformable_detr_imagenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-16T18:43:39.901Z\"\n",
            "},{\n",
            "    \"application\": \"Question Answering\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:58.627Z\",\n",
            "    \"description\": \"Question Answering Bert Base uncased model for extractive question answering on any provided content.\",\n",
            "    \"displayName\": \"Question Answering SQUAD2.0 Bert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NLP\",\n",
            "                \"SQUAD2.0\",\n",
            "                \"Riva\",\n",
            "                \"Question Answering\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 438459496,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"questionanswering_squad_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:53:45.108Z\"\n",
            "},{\n",
            "    \"application\": \"Speech To Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-11-11T00:46:33.666Z\",\n",
            "    \"description\": \"Arabic Conformer ASR model trained on RIVA ASR set\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Arabic\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"STT\",\n",
            "                \"Arabic\",\n",
            "                \"Riva\",\n",
            "                \"Conformer\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 486733079,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-RIVA.png\",\n",
            "    \"modelFormat\": \"ARPA\",\n",
            "    \"name\": \"speechtotext_ar_ar_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:07.211Z\"\n",
            "},{\n",
            "    \"application\": \"Domain Classification\",\n",
            "    \"createdDate\": \"2021-08-18T20:04:57.163Z\",\n",
            "    \"description\": \"Domain classification of the query for weather chat bot.\",\n",
            "    \"displayName\": \"Domain Classification English Bert\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NLP\",\n",
            "                \"Riva\",\n",
            "                \"Domain Classification\",\n",
            "                \"BERT\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 440794733,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"domainclassification_english_bert\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T14:52:44.125Z\"\n",
            "},{\n",
            "    \"application\": \"Object Pose Estimation\",\n",
            "    \"createdDate\": \"2024-03-12T17:38:14.126Z\",\n",
            "    \"description\": \"Single-stage, keypoint-based method for category-level object pose estimation\",\n",
            "    \"displayName\": \"Multiple 3D CenterPose\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"NSPECT-LE0M-BYPX\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_dla34\",\n",
            "    \"latestVersionSizeInBytes\": 73563852,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"multiclass_3d_centerpose\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:57:10.031Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-07-15T06:57:19.368Z\",\n",
            "    \"description\": \"French (fr-FR) Conformer ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR French\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
            "    \"latestVersionSizeInBytes\": 486733049,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_fr_fr_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:58:27.297Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2024-01-05T18:36:10.698Z\",\n",
            "    \"description\": \"TAO Pretrained DINO with Foundational Model Backbone\",\n",
            "    \"displayName\": \"TAO Pretrained DINO with Foundational Model Backbone\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Object Detection\",\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 3870977262,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"dino_with_fm_backbone\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-01-05T18:39:01.668Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-01-06T17:20:04.171Z\",\n",
            "    \"description\": \"Russian Citrinet ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Citrinet ASR Russian\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"ASR\",\n",
            "                \"STT\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Russian\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\",\n",
            "                \"Citrinet\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 566725641,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_ru_ru_citrinet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:55:29.345Z\"\n",
            "},{\n",
            "    \"application\": \"Open vocabulary instance segmentation\",\n",
            "    \"createdDate\": \"2024-08-23T01:04:30.495Z\",\n",
            "    \"description\": \"Open vocabulary multi-modal instance segmentation model trained on commercial data.\",\n",
            "    \"displayName\": \"Mask Grounding DINO\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"NSPECT-Y7JB-DQEW\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"mask_grounding_dino_swin_tiny_commercial_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 718739024,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"mask_grounding_dino\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-12T17:59:51.909Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-07-15T07:11:42.166Z\",\n",
            "    \"description\": \"Mandarin (zh-CN) Conformer ASR model trained on ASR set 2.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Mandarin\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
            "    \"latestVersionSizeInBytes\": 478130474,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_zh_cn_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:57:50.037Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2021-08-16T15:03:42.130Z\",\n",
            "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
            "    \"displayName\": \"DashCamNet\",\n",
            "    \"framework\": \"TAO Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NSPECT-HZG0-FMSH\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"AI\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"system\",\n",
            "            \"values\": [\n",
            "                \"signed models\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"hasSignedVersion\",\n",
            "            \"values\": [\n",
            "                \"true\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_onnx_v1.0.5\",\n",
            "    \"latestVersionSizeInBytes\": 5493121,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"dashcamnet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2025-03-17T16:57:20.472Z\"\n",
            "},{\n",
            "    \"application\": \"Speaker Diarization\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-12-01T22:42:08.577Z\",\n",
            "    \"description\": \"Neural VAD model used in Riva Speaker Diarization\",\n",
            "    \"displayName\": \"RIVA Diarizer Neural VAD\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"Speaker Recognition\",\n",
            "                \"Speaker Diarization\",\n",
            "                \"VAD\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 348955,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"diarizer_vad_multilingual_marblenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-04-04T20:01:32.816Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva EA\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-03-09T01:27:18.447Z\",\n",
            "    \"description\": \"Contains files used in rmir creation\",\n",
            "    \"displayName\": \"Riva TTS English US Auxiliary Files\",\n",
            "    \"framework\": \"Riva\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"Conversational AI\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Riva\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"n/a\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.3\",\n",
            "    \"latestVersionSizeInBytes\": 6815138,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"n/a\",\n",
            "    \"name\": \"speechsynthesis_en_us_auxiliary_files\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"n/a\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:22.265Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
            "    \"description\": \"Detect faces from an image.\",\n",
            "    \"displayName\": \"FaceDetect\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"NSPECT-J72I-5V5Z\",\n",
            "                \"Object Detection\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Public Safety\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"Retail\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Healthcare\",\n",
            "                \"DetectNet_v2\",\n",
            "                \"Computer Vision\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"pruned_quantized_v2.0.1\",\n",
            "    \"latestVersionSizeInBytes\": 5775090,\n",
            "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"facenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-11-27T22:08:21.927Z\"\n",
            "},{\n",
            "    \"application\": \"Speech To Text\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-04-08T04:37:39.406Z\",\n",
            "    \"description\": \"English Citrinet-256 ASR model trained on ASR set 2.0, no-weight-decay\",\n",
            "    \"displayName\": \"RIVA Citrinet 256 ASR English\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"asr\",\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
            "    \"latestVersionSizeInBytes\": 41140788,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"RIVA\",\n",
            "    \"name\": \"speechtotext_en_us_citrinet256\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:56:50.499Z\"\n",
            "},{\n",
            "    \"application\": \"NVIDIA Riva\",\n",
            "    \"builtBy\": \"aiapps\",\n",
            "    \"createdDate\": \"2022-09-12T20:02:49.888Z\",\n",
            "    \"description\": \"Riva Marblenet Voice Activity Detection\",\n",
            "    \"displayName\": \"Riva Marblenet Voice Activity Detection\",\n",
            "    \"framework\": \"NeMo\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"aiapps\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"NeMo\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp16\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 189576,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"voiceactivitydetection_marblenet\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp16\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:52:29.620Z\"\n",
            "},{\n",
            "    \"accessType\": \"LISTED\",\n",
            "    \"application\": \"Other\",\n",
            "    \"createdDate\": \"2024-10-02T01:22:37.919Z\",\n",
            "    \"description\": \"TAO Commercial Pretrained NV-CLIP ViT-H Model\",\n",
            "    \"displayName\": \"TAO Commercial Pretrained NV-CLIP Model\",\n",
            "    \"framework\": \"Other\",\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"CV\",\n",
            "                \"TAO\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Computer Vision\",\n",
            "                \"Deep Learning\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Other\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"productNames\",\n",
            "            \"values\": [\n",
            "                \"nv-ai-enterprise\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"nv_clip_336_vit_h_trainable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 1658465925,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"nvclip_vit\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"productNames\": [\n",
            "        \"n\",\n",
            "        \"v\",\n",
            "        \"-\",\n",
            "        \"a\",\n",
            "        \"i\",\n",
            "        \"-\",\n",
            "        \"e\",\n",
            "        \"n\",\n",
            "        \"t\",\n",
            "        \"e\",\n",
            "        \"r\",\n",
            "        \"p\",\n",
            "        \"r\",\n",
            "        \"i\",\n",
            "        \"s\",\n",
            "        \"e\"\n",
            "    ],\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-10-02T01:23:05.617Z\"\n",
            "},{\n",
            "    \"application\": \"Object Detection\",\n",
            "    \"createdDate\": \"2021-08-16T15:53:38.600Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained DetectNet V2\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Retail\",\n",
            "                \"CV\",\n",
            "                \"Metropolis\",\n",
            "                \"Industrial\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"TAO Toolkit\",\n",
            "                \"Inspection\",\n",
            "                \"Public Safety\",\n",
            "                \"DetectNet_v2\",\n",
            "                \"Smart Infrastructure\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"resnet34\",\n",
            "    \"latestVersionSizeInBytes\": 178944632,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_detectnet_v2\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:02:58.684Z\"\n",
            "},{\n",
            "    \"application\": \"Classification\",\n",
            "    \"createdDate\": \"2021-08-16T15:53:38.509Z\",\n",
            "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
            "    \"displayName\": \"TAO Pretrained Classification\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"DeepStream\",\n",
            "                \"Industrial\",\n",
            "                \"Smart Cities / Spaces\",\n",
            "                \"Inspection\",\n",
            "                \"Public Safety\",\n",
            "                \"EfficientNet\",\n",
            "                \"Smart Infrastructure\",\n",
            "                \"ResNet\",\n",
            "                \"Retail\",\n",
            "                \"Metropolis\",\n",
            "                \"CV\",\n",
            "                \"VGG\",\n",
            "                \"TAO Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"FP32\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
            "    \"latestVersionSizeInBytes\": 29955696,\n",
            "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
            "    \"modelFormat\": \"TLT\",\n",
            "    \"name\": \"pretrained_classification\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"FP32\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2024-08-19T05:02:22.751Z\"\n",
            "},{\n",
            "    \"application\": \"Speech to Text\",\n",
            "    \"builtBy\": \"NVIDIA\",\n",
            "    \"createdDate\": \"2022-10-06T21:20:23.015Z\",\n",
            "    \"description\": \"Korean (ko-KR) Conformer ASR model trained on ASR set 1.0\",\n",
            "    \"displayName\": \"RIVA Conformer ASR Korean\",\n",
            "    \"framework\": \"Transfer Learning Toolkit\",\n",
            "    \"isPublic\": true,\n",
            "    \"labels\": [\n",
            "        {\n",
            "            \"key\": \"builtBy\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"general\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA AI Enterprise Supported\",\n",
            "                \"Riva\",\n",
            "                \"NVIDIA AI\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"framework\",\n",
            "            \"values\": [\n",
            "                \"Transfer Learning Toolkit\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"precision\",\n",
            "            \"values\": [\n",
            "                \"fp32\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"key\": \"publisher\",\n",
            "            \"values\": [\n",
            "                \"NVIDIA\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
            "    \"latestVersionSizeInBytes\": 418150314,\n",
            "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
            "    \"modelFormat\": \"riva\",\n",
            "    \"name\": \"speechtotext_ko_kr_conformer\",\n",
            "    \"orgName\": \"nvidia\",\n",
            "    \"precision\": \"fp32\",\n",
            "    \"publisher\": \"NVIDIA\",\n",
            "    \"teamName\": \"tao\",\n",
            "    \"updatedDate\": \"2023-10-06T13:54:52.239Z\"\n",
            "}]\n"
          ]
        }
      ],
      "source": [
        "# 2.2\n",
        "# DO NOT CHANGE THIS CELL\n",
        "!ngc registry model list nvidia/tao/* --column name --column repository --column application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e46b6d8-bc0a-4db6-b0b7-285b8d0a2b78",
      "metadata": {
        "id": "8e46b6d8-bc0a-4db6-b0b7-285b8d0a2b78",
        "outputId": "bcc076af-851d-4d5d-ae86-c2609af6708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"download_end\": \"2025-08-01 07:07:41\",\n",
            "    \"download_start\": \"2025-08-01 07:07:40\",\n",
            "    \"download_time\": \"0s\",\n",
            "    \"files_downloaded\": 3,\n",
            "    \"local_path\": \"/dli/task/ngc_assets/dashcamnet_vpruned_v1.0\",\n",
            "    \"size_downloaded\": \"6.65 MB\",\n",
            "    \"status\": \"COMPLETED\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# 2.3\n",
        "!ngc registry model download-version nvidia/tao/dashcamnet:pruned_v1.0 --dest $NGC_DIR \\\n",
        "2>&1| tee my_assessment/answer_2.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c7764a-2126-44a3-b4d7-b18885d923d4",
      "metadata": {
        "id": "67c7764a-2126-44a3-b4d7-b18885d923d4"
      },
      "source": [
        "### Step 3: Edit the Inference Configuration File ###\n",
        "The next step is to modify the Gst-nvinfer configuration file that will be used to configure the AI inference plugin. You can create a new text file for this purpose manually and start from scratch or use the [template provided](spec_files/pgie_config_dashcamnet.txt). You can also refer to sample applications and configuration files [here](https://github.com/NVIDIA-AI-IOT/deepstream_python_apps). When creating the configuration file, below are the fields to pay attention to:\n",
        "\n",
        "Following properties are used when using TAO Toolkit models downloaded from NGC:\n",
        "* `tlt-encoded-model` - Pathname of the TAO Toolkit encoded model\n",
        "* `tlt-model-key` - Model load key for the TAO Toolkit encoded model\n",
        "* `labelfile-path` - Pathname of a text file containing the labels for the model\n",
        "* `int8-calib-file` - Pathname of the INT8 calibration file for dynamic range adjustment with an FP32 model (only in INT8)\n",
        "* `uff-input-blob-name` - Name of the input blob in the UFF file\n",
        "* `output-blob-names` - Array of output layer names\n",
        "* `infer-dims` - Dimensions of the model as [channel; height; width]\n",
        "* `net-scale-factor` - Pixel normalization factor _(default=1)_\n",
        "\n",
        "Recommended properties:\n",
        "* `batch-size` - Number of frames to be inferred together in a batch _(default=1)_\n",
        "\n",
        "Mandatory properties for detectors:\n",
        "* `num-detected-classes` - Number of classes detected by the network\n",
        "\n",
        "Optional properties for detectors:\n",
        "* `cluster-mode` - Clustering algorithm to use _(default=0 i.e. Group Rectangles)_\n",
        "* `interval` - Number of consecutive batches to be skipped for inference _(primary mode only | default=0)_\n",
        "\n",
        "Other optional properties:\n",
        "* `network-mode` - Data format to be used for inference _(0=FP32, 1=INT8, 2=FP16 mode | default=0 i.e. FP32)_\n",
        "* `process-mode` - Mode _(primary or secondary)_ in which the plugin is to operate on _(default=1 i.e. primary)_\n",
        "* `model-color-format` - Color format required by the model _(default=0 i.e. RGB)_\n",
        "* `gie-unique-id` - Unique ID to be assigned to the GIE to enable the application and other elements to identify detected bounding boxes and labels _(default=0)_\n",
        "* `model-engine-file` - Pathname of the serialized model engine file\n",
        "* `gpu-id` - Device ID of GPU to use for pre-processing/inference _(dGPU only)_\n",
        "\n",
        "**Note**: The values in the config file are overridden by values set through GObject properties. Another important thing to remember is that the properties recommended are specific to a primary detector, you will need to work on other properties for secondary and/or classifier. You can find most of the information needed on the [model card](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/tao/models/dashcamnet):\n",
        "\n",
        "<p><img src='images/model_card.png' width=720></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72dbcf79-4e80-4312-b462-d4aac1ff87e2",
      "metadata": {
        "id": "72dbcf79-4e80-4312-b462-d4aac1ff87e2"
      },
      "source": [
        "**Instructions**:\n",
        "<br>\n",
        "3.1. Open and review the [configuration file](spec_files/pgie_config_dashcamnet.txt). <br>\n",
        "3.2. Update the `<FIXME>`s _only_ in the configuration file with the correct values and **save changes**. Afterwards, make sure in the cell the correct path of the configuration file is referenced and execute the cell to mark your answer. _You can execute this cell multiple times until satisfactory_. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78da7d23-b3be-4166-a89b-0a9c941163a9",
      "metadata": {
        "id": "78da7d23-b3be-4166-a89b-0a9c941163a9",
        "outputId": "c1caee97-ade6-4297-f7ee-6db85e592485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dashcamnet_int8.txt  labels.txt  resnet18_dashcamnet_pruned.etlt\n"
          ]
        }
      ],
      "source": [
        "!ls /dli/task/ngc_assets/dashcamnet_vpruned_v1.0/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8e1e1e-0e46-49a3-9c34-e3f1bccee885",
      "metadata": {
        "id": "df8e1e1e-0e46-49a3-9c34-e3f1bccee885",
        "outputId": "ed525f54-0fd1-4fb5-c064-a1714792d32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[property]\n",
            "gpu-id=0\n",
            "net-scale-factor=1\n",
            "tlt-model-key=tlt_encode\n",
            "tlt-encoded-model=/dli/task/ngc_assets/dashcamnet_vpruned_v1.0/resnet18_dashcamnet_pruned.etlt\n",
            "labelfile-path=/dli/task/ngc_assets/dashcamnet_vpruned_v1.0/labels.txt\n",
            "infer-dims=3;544;960\n",
            "uff-input-blob-name=input_1\n",
            "batch-size=1\n",
            "process-mode=1\n",
            "model-color-format=0\n",
            "# 0=FP32, 1=INT8, 2=FP16 mode\n",
            "network-mode=0\n",
            "num-detected-classes=4\n",
            "interval=0\n",
            "gie-unique-id=1\n",
            "output-blob-names=output_bbox/BiasAdd;output_cov/Sigmoid\n",
            "cluster-mode=2\n",
            "\n",
            "# Use the config params below for NMS clustering mode\n",
            "[class-attrs-all]\n",
            "topk=20\n",
            "nms-iou-threshold=0.5\n",
            "pre-cluster-threshold=0.2'/dli/task/spec_files/pgie_config_dashcamnet.txt' -> 'my_assessment/answer_3.txt'\n"
          ]
        }
      ],
      "source": [
        "# 3.2\n",
        "os.environ['SPEC_FILE']='/dli/task/spec_files/pgie_config_dashcamnet.txt'\n",
        "\n",
        "# DO NOT CHANGE BELOW\n",
        "!cat $SPEC_FILE\n",
        "!cp -v $SPEC_FILE my_assessment/answer_3.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a547a77-8d64-4f83-b26d-91c9ee91edf3",
      "metadata": {
        "tags": [],
        "id": "2a547a77-8d64-4f83-b26d-91c9ee91edf3"
      },
      "source": [
        "### Step 4: Build and Run DeepStream Pipeline ###\n",
        "Next, it's time to build the pipeline. We're putting the pipeline creation and initiation procedure inside a function so it an be called easily. We also need to implement the probe callback function prior to running the pipeline. We've provided you a functional architecture and framework for this application to follow. Below is the architecture for this pipeline.\n",
        "\n",
        "<p><img src='images/assessment_pipeline.png' width=1080></p>\n",
        "\n",
        "Our logic for determining if a vehicle is tailgating will be based on the coordinates of detected objects' bounding boxes shown below:\n",
        "\n",
        "<p><img src='images/tailgate_metrics.png' width=720></p>\n",
        "\n",
        "While we attached the probe to the _nvdsosd_ plugin, the only requirement is that it has to be after the _nvinfer_ plugin so it contains the AI-infered metadata. Recall that we need to program the probe [callback function](https://en.wikipedia.org/wiki/Callback_(computer_programming)) to provide us a signal when tailgating is potentially occuring. The probe callback function generally follows a boilerplate, to help iterate through the batches, frames, and objects. For more information on how to implement a callback function, please refer to the [GStreamer Probe documentation](https://gstreamer.freedesktop.org/documentation/additional/design/probes.html).\n",
        "\n",
        "<p><img src='images/probe_boiler_plate.png' width=720></p>\n",
        "\n",
        "We want to generate a list that will contain 0s and 1s for each frame to represent if it exhibits tailgating. Therefore there should be as many numbers as there are number of frames in the end. There should _not_ be one number associated with each object detected as it will lead to more than one number associated with each frame. Below is a sample output:\n",
        "\n",
        "<p><img src='images/sample_log.png' width=720></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a860bbe9-b937-47af-a305-95c00d36f580",
      "metadata": {
        "id": "a860bbe9-b937-47af-a305-95c00d36f580"
      },
      "source": [
        "**Instructions**:\n",
        "<br>\n",
        "4.1. Review the pipeline architecture. <br>\n",
        "4.2. Modify the `<FIXME>` _only_ in the cell with the correct code and execute the cell to define the function that will build and run the pipeline. <br>\n",
        "4.3. Modify the `<FIXME>` _only_ in the cell with the correct code and execute the cell to define the probe callback function. <br>\n",
        "4.4. Execute the cell to run the pipeline. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9d8b9c-b28b-4d8f-b226-70ca5b76e6ad",
      "metadata": {
        "id": "da9d8b9c-b28b-4d8f-b226-70ca5b76e6ad"
      },
      "outputs": [],
      "source": [
        "# 4.2\n",
        "#Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import gi\n",
        "gi.require_version('Gst', '1.0')\n",
        "from gi.repository import GObject, Gst, GLib\n",
        "from common.bus_call import bus_call\n",
        "import pyds\n",
        "\n",
        "def run(input_file_path):\n",
        "    global inference_output\n",
        "    inference_output=[]\n",
        "    Gst.init(None)\n",
        "\n",
        "    # Create element that will form a pipeline\n",
        "    print(\"Creating Pipeline\")\n",
        "    pipeline=Gst.Pipeline()\n",
        "\n",
        "    source=Gst.ElementFactory.make(\"filesrc\", \"file-source\")\n",
        "    source.set_property('location', input_file_path)\n",
        "    h264parser=Gst.ElementFactory.make(\"h264parse\", \"h264-parser\")\n",
        "    decoder=Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
        "\n",
        "    streammux=Gst.ElementFactory.make(\"nvstreammux\", \"Stream-muxer\")\n",
        "    streammux.set_property('width', 1280)\n",
        "    streammux.set_property('height', 720)\n",
        "    streammux.set_property('batch-size', 1)\n",
        "\n",
        "    pgie=Gst.ElementFactory.make(\"nvinfer\", \"primary-inference\")\n",
        "    pgie.set_property('config-file-path', os.environ['SPEC_FILE'])\n",
        "\n",
        "    nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor1\")\n",
        "    nvosd=Gst.ElementFactory.make(\"nvdsosd\", \"onscreendisplay\")\n",
        "    nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
        "    capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
        "    caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
        "    capsfilter.set_property(\"caps\", caps)\n",
        "\n",
        "    encoder=Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
        "    encoder.set_property(\"bitrate\", 2000000)\n",
        "\n",
        "    sink=Gst.ElementFactory.make(\"filesink\", 'filesink')\n",
        "    sink.set_property('location', 'output.mpeg4')\n",
        "    sink.set_property(\"sync\", 1)\n",
        "\n",
        "    # Add the elements to the pipeline\n",
        "    print(\"Adding elements to Pipeline\")\n",
        "    pipeline.add(source)\n",
        "    pipeline.add(h264parser)\n",
        "    pipeline.add(decoder)\n",
        "    pipeline.add(streammux)\n",
        "    pipeline.add(pgie)\n",
        "    pipeline.add(nvvidconv1)\n",
        "    pipeline.add(nvosd)\n",
        "    pipeline.add(nvvidconv2)\n",
        "    pipeline.add(capsfilter)\n",
        "    pipeline.add(encoder)\n",
        "    pipeline.add(sink)\n",
        "\n",
        "    # Link the elements together\n",
        "    print(\"Linking elements in the Pipeline\")\n",
        "    source.link(h264parser)\n",
        "    h264parser.link(decoder)\n",
        "    decoder.get_static_pad('src').link(streammux.get_request_pad(\"sink_0\"))\n",
        "    streammux.link(pgie)\n",
        "    pgie.link(nvvidconv1)\n",
        "    nvvidconv1.link(nvosd)\n",
        "    nvosd.link(nvvidconv2)\n",
        "    nvvidconv2.link(capsfilter)\n",
        "    capsfilter.link(encoder)\n",
        "    encoder.link(sink)\n",
        "\n",
        "    # Attach probe to OSD sink pad\n",
        "    osdsinkpad = nvosd.get_static_pad(\"sink\")\n",
        "    osdsinkpad.add_probe(Gst.PadProbeType.BUFFER, osd_sink_pad_buffer_probe, 0)\n",
        "\n",
        "    # Create an event loop and feed gstreamer bus mesages to it\n",
        "    loop=GLib.MainLoop()\n",
        "    bus=pipeline.get_bus()\n",
        "    bus.add_signal_watch()\n",
        "    bus.connect(\"message\", bus_call, loop)\n",
        "\n",
        "    # Start play back and listen to events\n",
        "    print(\"Starting pipeline\")\n",
        "\n",
        "    pipeline.set_state(Gst.State.PLAYING)\n",
        "    try:\n",
        "        loop.run()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    pipeline.set_state(Gst.State.NULL)\n",
        "    return inference_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3d3a5e2-aa96-463a-b9e5-bdf69b48bc38",
      "metadata": {
        "id": "f3d3a5e2-aa96-463a-b9e5-bdf69b48bc38"
      },
      "outputs": [],
      "source": [
        "# 4.3\n",
        "# Define the Probe Function\n",
        "def osd_sink_pad_buffer_probe(pad, info, u_data):\n",
        "    gst_buffer=info.get_buffer()\n",
        "\n",
        "    # Retrieve batch metadata from the gst_buffer\n",
        "    batch_meta=pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
        "    l_frame=batch_meta.frame_meta_list\n",
        "    while l_frame is not None:\n",
        "\n",
        "        # Initially set the tailgate indicator to False for each frame\n",
        "        tailgate=False\n",
        "        try:\n",
        "            frame_meta=pyds.NvDsFrameMeta.cast(l_frame.data)\n",
        "        except StopIteration:\n",
        "            break\n",
        "        frame_number=frame_meta.frame_num\n",
        "        l_obj=frame_meta.obj_meta_list\n",
        "\n",
        "        # Iterate through each object to check its dimension\n",
        "        while l_obj is not None:\n",
        "            try:\n",
        "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
        "\n",
        "                # If the object meet the criteria then set tailgate indicator to True\n",
        "                obj_bottom=obj_meta.rect_params.top + obj_meta.rect_params.height\n",
        "                if (obj_meta.rect_params.width > FRAME_WIDTH * .3) & (obj_bottom > FRAME_HEIGHT * .9):\n",
        "                    tailgate=True\n",
        "\n",
        "            except StopIteration:\n",
        "                break\n",
        "            try:\n",
        "                l_obj=l_obj.next\n",
        "            except StopIteration:\n",
        "                break\n",
        "\n",
        "        print(f'Analyzing frame {frame_number}', end='\\r')\n",
        "        inference_output.append(str(int(tailgate)))\n",
        "        try:\n",
        "            l_frame=l_frame.next\n",
        "        except StopIteration:\n",
        "            break\n",
        "    return Gst.PadProbeReturn.OK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fef2c16-93b6-4c59-abdc-cd4409cba488",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "1fef2c16-93b6-4c59-abdc-cd4409cba488",
        "outputId": "26cd7a87-640e-459b-dc0d-27cc4474b9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Pipeline\n",
            "Adding elements to Pipeline\n",
            "Linking elements in the Pipeline\n",
            "Starting pipeline\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0:09:19.619870644 \u001b[336m   71\u001b[00m      0x45694c0 \u001b[36mINFO   \u001b[00m \u001b[00m             nvinfer gstnvinfer.cpp:682:gst_nvinfer_logger:<primary-inference>\u001b[00m NvDsInferContext[UID 1]: Info from NvDsInferContextImpl::buildModel() <nvdsinfer_context_impl.cpp:2002> [UID = 1]: Trying to create engine from model files\n",
            "ERROR: [TRT]: 3: [builder.cpp::~Builder::307] Error Code 3: API Usage Error (Parameter check failed at: optimizer/api/builder.cpp::~Builder::307, condition: mObjectCounter.use_count() == 1. Destroying a builder object before destroying objects it created leads to undefined behavior.\n",
            ")\n",
            "0:09:29.070852857 \u001b[336m   71\u001b[00m      0x45694c0 \u001b[36mINFO   \u001b[00m \u001b[00m             nvinfer gstnvinfer.cpp:682:gst_nvinfer_logger:<primary-inference>\u001b[00m NvDsInferContext[UID 1]: Info from NvDsInferContextImpl::buildModel() <nvdsinfer_context_impl.cpp:2034> [UID = 1]: serialize cuda engine to file: /dli/task/ngc_assets/dashcamnet_vpruned_v1.0/resnet18_dashcamnet_pruned.etlt_b1_gpu0_fp32.engine successfully\n",
            "0:09:29.132015686 \u001b[336m   71\u001b[00m      0x45694c0 \u001b[36mINFO   \u001b[00m \u001b[00m             nvinfer gstnvinfer_impl.cpp:328:notifyLoadModelStatus:<primary-inference>\u001b[00m [UID 1]: Load new model:/dli/task/spec_files/pgie_config_dashcamnet.txt sucessfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: [TRT]: The implicit batch dimension mode has been deprecated. Please create the network with NetworkDefinitionCreationFlag::kEXPLICIT_BATCH flag whenever possible.\n",
            "INFO: ../nvdsinfer/nvdsinfer_model_builder.cpp:610 [Implicit Engine Info]: layers num: 3\n",
            "0   INPUT  kFLOAT input_1         3x544x960       \n",
            "1   OUTPUT kFLOAT output_bbox/BiasAdd 16x34x60        \n",
            "2   OUTPUT kFLOAT output_cov/Sigmoid 4x34x60         \n",
            "\n",
            "nvstreammux: Successfully handled EOS for source_id=0\n",
            "End-of-streamme 2405"
          ]
        }
      ],
      "source": [
        "# 4.4\n",
        "tailgate_log=run(input_file_path='/dli/task/data/assessment_stream.h264')\n",
        "\n",
        "# DO NOT CHANGE BELOW\n",
        "with open('/dli/task/my_assessment/answer_4.txt', 'w') as f:\n",
        "    f.write('\\n'.join(tailgate_log))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92642fe5-6bbe-45eb-9ed7-5d4cce4a8a59",
      "metadata": {
        "id": "92642fe5-6bbe-45eb-9ed7-5d4cce4a8a59"
      },
      "source": [
        "## Step 5: Analyze the Results ##\n",
        "Finally, we can analyze the driving behavior using the log we've collected."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11858951-c2bb-4ca1-a921-55f9287fbbd0",
      "metadata": {
        "id": "11858951-c2bb-4ca1-a921-55f9287fbbd0"
      },
      "source": [
        "**Instructions**: <br>\n",
        "5.1. Execute the cell to import the tailgate log into a Pandas DataFrame. <br>\n",
        "5.2. Execute the cell to plot the occurences of tailgating. <br>\n",
        "5.3. Make sure the output `.mp4` file is being referenced and execute the cell to view the composite with the bounding boxes drawn into the original video. <br>\n",
        "5.4. Execute the cell to calculate the amount of time on average this vehicle spent tailgating. <br>\n",
        "5.5. Modify the `<FIXME>` _only_ to mark your answer. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80436323-269b-4010-8482-167861e93d16",
      "metadata": {
        "id": "80436323-269b-4010-8482-167861e93d16",
        "outputId": "53a85cba-0faa-440b-fdea-4abbe5e7ff73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   inference\n",
              "0          1\n",
              "1          1\n",
              "2          1\n",
              "3          1\n",
              "4          1"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5.1\n",
        "# DO NOT CHANGE THIS CELL\n",
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv('my_assessment/answer_4.txt', names=['inference'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da127db-2687-41c2-a026-8988a4bbe8ba",
      "metadata": {
        "id": "1da127db-2687-41c2-a026-8988a4bbe8ba",
        "outputId": "1a42d716-d598-4365-c921-4f04da6ef0b5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 3000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5.2\n",
        "# DO NOT CHANGE THIS CELL\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "df.plot(kind='bar', figsize=(30, 5))\n",
        "plt.xticks(np.arange(0, len(df)+1, FRAME_RATE), np.arange(0, len(df)/FRAME_RATE))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523d15a0-9374-419a-869b-b353fc35de36",
      "metadata": {
        "id": "523d15a0-9374-419a-869b-b353fc35de36",
        "outputId": "abe50891-6f5d-4741-b5f5-213e65473ecf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video src=\"output_converted.mp4\" controls  width=\"720\" >\n",
              "      Your browser does not support the <code>video</code> element.\n",
              "    </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5.3\n",
        "# DO NOT CHANGE THIS CELL\n",
        "!ffmpeg -i output.mpeg4 output_converted.mp4 -y -loglevel quiet\n",
        "\n",
        "Video('output_converted.mp4', width=720)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ae0b43f-23e1-4ab9-8fb7-0fec6ac7caaa",
      "metadata": {
        "id": "4ae0b43f-23e1-4ab9-8fb7-0fec6ac7caaa",
        "outputId": "3ec0e7d4-8423-480f-d7cb-a735b0260d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    0.990025\n",
              "0    0.009975\n",
              "Name: inference, dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 5.4\n",
        "# DO NOT CHANGE THIS CELL\n",
        "display(df['inference'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983d0dc4-9f3c-4396-b4c0-5e52ba303f43",
      "metadata": {
        "id": "983d0dc4-9f3c-4396-b4c0-5e52ba303f43"
      },
      "outputs": [],
      "source": [
        "# Question: How much time (without the percentage sign, e.g. 5.0) did the vehicle tailgate?\n",
        "Answer=5.0\n",
        "\n",
        "# EXAMPLE:\n",
        "# Answer='5.0'\n",
        "\n",
        "# DO NOT CHANGE BELOW\n",
        "!echo $Answer > my_assessment/answer_5.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "348c075a-6f39-4483-9035-af9ac9f65a5c",
      "metadata": {
        "id": "348c075a-6f39-4483-9035-af9ac9f65a5c"
      },
      "source": [
        "## Grade Your Code ##\n",
        "If you have completed all 5 questions and confirmed the pipeline runs correctly, save changes to the notebook and revisit the webpage where you launched this interactive environment. Click on the \"**ASSESS TASK**\" button as shown in the screenshot below. Doing so will give you credit for this part of the lab that counts towards earning a certificate of competency for the entire course.\n",
        "\n",
        "<p><img src='images/credit.png' width=1080></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d2b3429-e152-4ffb-a09d-2945ab3582bc",
      "metadata": {
        "id": "2d2b3429-e152-4ffb-a09d-2945ab3582bc"
      },
      "source": [
        "### BONUS. Visualizing Frames ###\n",
        "Below we have included some helpful functions that will help you visualize the frames that exhibit tailgating behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74e0ee86-e27c-48c5-9274-de08cd3aa6fe",
      "metadata": {
        "id": "74e0ee86-e27c-48c5-9274-de08cd3aa6fe"
      },
      "source": [
        "**Instructions**: <br>\n",
        "B.1. Execute the cell to extract tailgating frames. <br>\n",
        "B.2. Execute the cell to display randomly selected tailgating frames. <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5967bf7f-4332-4965-b713-c424e62d0dbb",
      "metadata": {
        "id": "5967bf7f-4332-4965-b713-c424e62d0dbb"
      },
      "outputs": [],
      "source": [
        "# B.1\n",
        "# DO NOT CHANGE THIS CELL\n",
        "import cv2\n",
        "\n",
        "!mkdir output_images\n",
        "!rm -r output_images/*\n",
        "input_video=cv2.VideoCapture('output_converted.mp4')\n",
        "retVal, im=input_video.read()\n",
        "frameCount=0\n",
        "while retVal:\n",
        "    if frameCount in df[df['inference']==1].index:\n",
        "        cv2.imwrite(\"output_images/frame_%d.jpg\" % frameCount, im)     # save frame as JPEG file\n",
        "    retVal, im=input_video.read()\n",
        "    print(f'Read a new frame: {frameCount}', end='\\r')\n",
        "    frameCount+=1\n",
        "input_video.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a87a09-d228-4c79-b831-868ebeb58a7f",
      "metadata": {
        "id": "c3a87a09-d228-4c79-b831-868ebeb58a7f"
      },
      "outputs": [],
      "source": [
        "# B.2\n",
        "# DO NOT CHANGE THIS CELL\n",
        "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
        "from matplotlib.pyplot import imshow\n",
        "import numpy as np\n",
        "\n",
        "def plot_random_samples(frames):\n",
        "    sample_frames = np.random.choice(frames,size=8)\n",
        "    fig=plt.figure(figsize=(30, 8))\n",
        "    columns = 4\n",
        "    rows = 2\n",
        "    i = 1\n",
        "    for frame_num in sample_frames:\n",
        "        # im = Image.open('{}/images/{}/{}.jpg'.format(config[\"Base_Dest_Folder\"], config[\"Test_Video_ID\"], box[\"frame_no\"]))\n",
        "        im = Image.open(f'output_images/frame_{frame_num}.jpg')\n",
        "        fig.add_subplot(rows, columns, i)\n",
        "        i += 1\n",
        "        plt.imshow(np.asarray(im))\n",
        "    plt.show()\n",
        "\n",
        "plot_random_samples(df[df['inference']==1].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6b7f52a-c910-4b48-89ee-b241320f0697",
      "metadata": {
        "id": "b6b7f52a-c910-4b48-89ee-b241320f0697"
      },
      "source": [
        "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}